{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "lAdV5KBbaqD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download and unzip Dataset**"
      ],
      "metadata": {
        "id": "kzuvZlwT1G4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset\n",
        "!gdown 1h_Xi0ms4kpCvzSsMOsGfhhUqYezXk3s_\n",
        "\n",
        "# unzip dataset\n",
        "!unzip \"/content/dataset.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1GUvtVQauic",
        "outputId": "02df03ec-1b64-4e38-910f-cdbb9174d5a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1h_Xi0ms4kpCvzSsMOsGfhhUqYezXk3s_\n",
            "To: /content/dataset.zip\n",
            "100% 2.39G/2.39G [00:23<00:00, 103MB/s]\n",
            "Archive:  /content/dataset.zip\n",
            "  inflating: dataset/subj_1.mat      \n",
            "  inflating: dataset/subj_10.mat     \n",
            "  inflating: dataset/subj_11.mat     \n",
            "  inflating: dataset/subj_12.mat     \n",
            "  inflating: dataset/subj_13.mat     \n",
            "  inflating: dataset/subj_14.mat     \n",
            "  inflating: dataset/subj_15.mat     \n",
            "  inflating: dataset/subj_2.mat      \n",
            "  inflating: dataset/subj_3.mat      \n",
            "  inflating: dataset/subj_4.mat      \n",
            "  inflating: dataset/subj_5.mat      \n",
            "  inflating: dataset/subj_6.mat      \n",
            "  inflating: dataset/subj_7.mat      \n",
            "  inflating: dataset/subj_8.mat      \n",
            "  inflating: dataset/subj_9.mat      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and import"
      ],
      "metadata": {
        "id": "r80h9yXJ1Ncp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install requiered library**"
      ],
      "metadata": {
        "id": "S3nEnfAuavVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create requirements.txt \n",
        "libraries = [\n",
        "    'numpy',\n",
        "    'scipy',\n",
        "    'gdown',\n",
        "    'scikit-learn',\n",
        "    'mne'\n",
        "]\n",
        "\n",
        "with open('requirements.txt', 'w') as file:\n",
        "    for library in libraries:\n",
        "        file.write(library + '\\n')      "
      ],
      "metadata": {
        "id": "8snNTyk9AEeB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWJk6j0kAPC3",
        "outputId": "a9f1fa3f-54a4-4e9c-cdf1-16af197b795d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.6.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.2.2)\n",
            "Collecting mne (from -r requirements.txt (line 5))\n",
            "  Downloading mne-1.4.2-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 3)) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 3)) (4.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne->-r requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne->-r requirements.txt (line 5)) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne->-r requirements.txt (line 5)) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne->-r requirements.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne->-r requirements.txt (line 5)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne->-r requirements.txt (line 5)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne->-r requirements.txt (line 5)) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (1.7.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "yFywxaBVazy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from mne.decoding import CSP"
      ],
      "metadata": {
        "id": "5jeaftMkbKre"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train 1 Model for ALL 15 person data  - Split Leave one out\n",
        "\n",
        "Train only one model and evaluate model on unseen data"
      ],
      "metadata": {
        "id": "dlEyN8Xs1swt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess data all data**"
      ],
      "metadata": {
        "id": "O61HNXFDbLJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the channels of interest\n",
        "channels_of_interest = [11, 40, 12, 41, 13, 42, 14, 44, 16, 45, 17, 46, 18, 47, 20, 49, 21, 50, 22, 51, 23]\n",
        "\n",
        "# Initialize empty lists for X and Y data\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "min_num_trials = float('inf')  # Initialize with a large value\n",
        "\n",
        "# Loop over each person's data\n",
        "for i in range(1, 16):\n",
        "    # Load the .mat file for each person\n",
        "    data = loadmat(f'dataset/subj_{i}.mat')['data'][0]\n",
        "\n",
        "    # Extract the classes\n",
        "    class_1 = data[0][:, channels_of_interest, :]\n",
        "    class_2 = data[1][:, channels_of_interest, :]\n",
        "    class_3 = data[2][:, channels_of_interest, :]\n",
        "    class_4 = data[3][:, channels_of_interest, :]\n",
        "\n",
        "    # Determine the minimum number of trials among all classes\n",
        "    min_num_trials = min(min_num_trials, class_1.shape[2], class_2.shape[2], class_3.shape[2], class_4.shape[2])\n",
        "\n",
        "    # Append the data to X and Y\n",
        "    X.append(class_1[:, :, :min_num_trials])\n",
        "    X.append(class_2[:, :, :min_num_trials])\n",
        "    X.append(class_3[:, :, :min_num_trials])\n",
        "    X.append(class_4[:, :, :min_num_trials])\n",
        "\n",
        "    # Create labels for the classes\n",
        "    num_samples = min_num_trials * 4\n",
        "    labels = np.zeros((num_samples,))\n",
        "    labels[min_num_trials:min_num_trials * 2] = 1\n",
        "    labels[min_num_trials * 2:min_num_trials * 3] = 2\n",
        "    labels[min_num_trials * 3:] = 3\n",
        "\n",
        "    # Append the labels to Y\n",
        "    Y.append(labels)\n",
        "\n",
        "# Concatenate the data for all people\n",
        "X = np.concatenate(X, axis=2)\n",
        "Y = np.concatenate(Y, axis=0)\n",
        "\n",
        "# Reshape X to match the required shape\n",
        "X = X.transpose((2, 1, 0))  \n"
      ],
      "metadata": {
        "id": "UOVJq4ocbID5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Leave one Out Split**"
      ],
      "metadata": {
        "id": "awhSW56l9LD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists for train and test sets\n",
        "X_train = []\n",
        "X_test = []\n",
        "Y_train = []\n",
        "Y_test = []\n",
        "\n",
        "# Split the data using leave-one-out method\n",
        "for i in range(min_num_trials):\n",
        "    X_train.append(np.concatenate([X[Y != j, :, :] for j in range(4)], axis=0))\n",
        "    X_test.append(X[Y == i, :, :])\n",
        "    Y_train.append(np.concatenate([Y[Y != j] for j in range(4)], axis=0))\n",
        "    Y_test.append(Y[Y == i])\n",
        "\n",
        "# Convert lists to arrays\n",
        "X_train = np.concatenate(X_train, axis=0)\n",
        "X_test = np.concatenate(X_test, axis=0)\n",
        "Y_train = np.concatenate(Y_train, axis=0)\n",
        "Y_test = np.concatenate(Y_test, axis=0)\n",
        "\n",
        "# Create separate datasets for each class\n",
        "X1_train = X_train[Y_train == 0]\n",
        "X2_train = X_train[Y_train == 1]\n",
        "X3_train = X_train[Y_train == 2]\n",
        "X4_train = X_train[Y_train == 3]\n",
        "\n",
        "X1_train = X1_train[np.logical_not(np.isnan(np.sum(X1_train, axis=(1, 2))) | np.isinf(np.sum(X1_train, axis=(1, 2))))]\n",
        "X2_train = X2_train[np.logical_not(np.isnan(np.sum(X2_train, axis=(1, 2))) | np.isinf(np.sum(X2_train, axis=(1, 2))))]\n",
        "X3_train = X3_train[np.logical_not(np.isnan(np.sum(X3_train, axis=(1, 2))) | np.isinf(np.sum(X3_train, axis=(1, 2))))]\n",
        "X4_train = np.nan_to_num(X4_train)\n",
        "\n",
        "X1_test = X_test[Y_test == 0]\n",
        "X2_test = X_test[Y_test == 1]\n",
        "X3_test = X_test[Y_test == 2]\n",
        "X4_test = X_test[Y_test == 3]\n",
        "\n",
        "X1_test = X1_test[np.logical_not(np.isnan(np.sum(X1_test, axis=(1, 2))) | np.isinf(np.sum(X1_test, axis=(1, 2))))]\n",
        "X2_test = X2_test[np.logical_not(np.isnan(np.sum(X2_test, axis=(1, 2))) | np.isinf(np.sum(X2_test, axis=(1, 2))))]\n",
        "X3_test = X3_test[np.logical_not(np.isnan(np.sum(X3_test, axis=(1, 2))) | np.isinf(np.sum(X3_test, axis=(1, 2))))]\n",
        "X4_test = np.nan_to_num(X4_test)"
      ],
      "metadata": {
        "id": "N_FM3MRO9Igb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create 3 Classifiers**"
      ],
      "metadata": {
        "id": "6SCQPmNP-xtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 4 vs. Other Classes Classifier\n",
        "X_classifier1_train = np.concatenate((X1_train, X2_train, X3_train, X4_train), axis=0)\n",
        "y_classifier1_train = np.concatenate((np.ones(X1_train.shape[0]), np.ones(X2_train.shape[0]),\n",
        "                                      np.ones(X3_train.shape[0]), np.zeros(X4_train.shape[0])))\n",
        "\n",
        "X_classifier1_test = np.concatenate((X1_test, X2_test, X3_test, X4_test), axis=0)\n",
        "y_classifier1_test = np.concatenate((np.ones(X1_test.shape[0]), np.ones(X2_test.shape[0]),\n",
        "                                    np.ones(X3_test.shape[0]), np.zeros(X4_test.shape[0])))\n",
        "\n",
        "# Apply CSP to X_classifier1 train and test data\n",
        "csp1 = CSP(n_components=32, reg=None, log=True)\n",
        "X_classifier1_train_csp = csp1.fit_transform(X_classifier1_train, y_classifier1_train)\n",
        "X_classifier1_test_csp = csp1.transform(X_classifier1_test)\n",
        "\n",
        "# Train LDA on X_classifier1 train data\n",
        "lda1 = LinearDiscriminantAnalysis()\n",
        "lda1.fit(X_classifier1_train_csp, y_classifier1_train)\n",
        "\n",
        "# Predict on train and test data\n",
        "y_classifier1_train_pred = lda1.predict(X_classifier1_train_csp)\n",
        "y_classifier1_test_pred = lda1.predict(X_classifier1_test_csp)\n",
        "\n",
        "# Calculate accuracy for Class 4 vs. Other Classes Classifier\n",
        "accuracy_train1 = accuracy_score(y_classifier1_train, y_classifier1_train_pred)\n",
        "accuracy_test1 = accuracy_score(y_classifier1_test, y_classifier1_test_pred)\n",
        "\n",
        "# Calculate confusion matrices for Class 4 vs. Other Classes Classifier\n",
        "confusion_matrix_train1 = confusion_matrix(y_classifier1_train, y_classifier1_train_pred)\n",
        "confusion_matrix_test1 = confusion_matrix(y_classifier1_test, y_classifier1_test_pred)\n",
        "\n",
        "# Class 3 vs. (Class 1 and 2) Classifier\n",
        "X_classifier2_train = np.concatenate((X3_train, X1_train, X2_train), axis=0)\n",
        "y_classifier2_train = np.concatenate((np.zeros(X3_train.shape[0]), np.ones(X1_train.shape[0]),\n",
        "                                      np.ones(X2_train.shape[0])))\n",
        "\n",
        "X_classifier2_test = np.concatenate((X3_test, X1_test, X2_test), axis=0)\n",
        "y_classifier2_test = np.concatenate((np.zeros(X3_test.shape[0]), np.ones(X1_test.shape[0]),\n",
        "                                    np.ones(X2_test.shape[0])))\n",
        "\n",
        "# Apply CSP to X_classifier2 train and test data\n",
        "csp2 = CSP(n_components=32, reg=None, log=True)\n",
        "X_classifier2_train_csp = csp2.fit_transform(X_classifier2_train, y_classifier2_train)\n",
        "X_classifier2_test_csp = csp2.transform(X_classifier2_test)\n",
        "\n",
        "# Train LDA on X_classifier2 train data\n",
        "lda2 = LinearDiscriminantAnalysis()\n",
        "lda2.fit(X_classifier2_train_csp, y_classifier2_train)\n",
        "\n",
        "# Predict on train and test data\n",
        "y_classifier2_train_pred = lda2.predict(X_classifier2_train_csp)\n",
        "y_classifier2_test_pred = lda2.predict(X_classifier2_test_csp)\n",
        "\n",
        "# Calculate accuracy for Class 3 vs. (Class 1 and 2) Classifier\n",
        "accuracy_train2 = accuracy_score(y_classifier2_train, y_classifier2_train_pred)\n",
        "accuracy_test2 = accuracy_score(y_classifier2_test, y_classifier2_test_pred)\n",
        "\n",
        "# Calculate confusion matrices for Class 3 vs. (Class 1 and 2) Classifier\n",
        "confusion_matrix_train2 = confusion_matrix(y_classifier2_train, y_classifier2_train_pred)\n",
        "confusion_matrix_test2 = confusion_matrix(y_classifier2_test, y_classifier2_test_pred)\n",
        "\n",
        "# Class 1 vs. Class 2 Classifier\n",
        "X_classifier3_train = np.concatenate((X1_train, X2_train), axis=0)\n",
        "y_classifier3_train = np.concatenate((np.zeros(X1_train.shape[0]), np.ones(X2_train.shape[0])))\n",
        "\n",
        "X_classifier3_test = np.concatenate((X1_test, X2_test), axis=0)\n",
        "y_classifier3_test = np.concatenate((np.zeros(X1_test.shape[0]), np.ones(X2_test.shape[0])))\n",
        "\n",
        "# Apply CSP to X_classifier3 train and test data\n",
        "csp3 = CSP(n_components=32, reg=None, log=True)\n",
        "X_classifier3_train_csp = csp3.fit_transform(X_classifier3_train, y_classifier3_train)\n",
        "X_classifier3_test_csp = csp3.transform(X_classifier3_test)\n",
        "\n",
        "# Train LDA on X_classifier3 train data\n",
        "lda3 = LinearDiscriminantAnalysis()\n",
        "lda3.fit(X_classifier3_train_csp, y_classifier3_train)\n",
        "\n",
        "# Predict on train and test data\n",
        "y_classifier3_train_pred = lda3.predict(X_classifier3_train_csp)\n",
        "y_classifier3_test_pred = lda3.predict(X_classifier3_test_csp)\n",
        "\n",
        "# Calculate accuracy for Class 1 vs. Class 2 Classifier\n",
        "accuracy_train3 = accuracy_score(y_classifier3_train, y_classifier3_train_pred)\n",
        "accuracy_test3 = accuracy_score(y_classifier3_test, y_classifier3_test_pred)\n",
        "\n",
        "# Calculate confusion matrices for Class 1 vs. Class 2 Classifier\n",
        "confusion_matrix_train3 = confusion_matrix(y_classifier3_train, y_classifier3_train_pred)\n",
        "confusion_matrix_test3 = confusion_matrix(y_classifier3_test, y_classifier3_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKd-s3cg-Q93",
        "outputId": "30042587-8241-4e93-8021-a9a03ca1cdc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.7e+02 (2.2e-16 eps * 21 dim * 5.8e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.3e+02 (2.2e-16 eps * 21 dim * 7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.7e+02 (2.2e-16 eps * 21 dim * 3.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.7e+02 (2.2e-16 eps * 21 dim * 5.9e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2e+02 (2.2e-16 eps * 21 dim * 4.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.9e+02 (2.2e-16 eps * 21 dim * 4.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate on All Test and Train**"
      ],
      "metadata": {
        "id": "oEe75pSw-2aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all X train and test data\n",
        "X_all_train = np.concatenate((X1_train, X2_train, X3_train, X4_train), axis=0)\n",
        "X_all_test = np.concatenate((X1_test, X2_test, X3_test, X4_test), axis=0)\n",
        "\n",
        "# Combine all y train and test data\n",
        "y_all_train = np.concatenate((np.zeros(X1_train.shape[0]), np.ones(X2_train.shape[0]), np.ones(X3_train.shape[0])*2, np.ones(X4_train.shape[0])*3))\n",
        "y_all_test = np.concatenate((np.zeros(X1_test.shape[0]), np.ones(X2_test.shape[0]), np.ones(X3_test.shape[0])*2, np.ones(X4_test.shape[0])*3))\n",
        "\n",
        "# Evaluate the cascade of classifiers on the test data\n",
        "y_pred_all_train = []\n",
        "y_pred_all_test = []\n",
        "\n",
        "for x_train in X_all_train:\n",
        "    x_train_csp1 = csp1.transform(np.array([x_train]))\n",
        "    x_train_csp2 = csp2.transform(np.array([x_train]))\n",
        "    x_train_csp3 = csp3.transform(np.array([x_train]))\n",
        "\n",
        "    if lda1.predict(x_train_csp1) == 1:\n",
        "        if lda2.predict(x_train_csp2) == 1:\n",
        "            if lda3.predict(x_train_csp3) == 1:\n",
        "                y_pred_all_train.append(1)\n",
        "            else:\n",
        "                y_pred_all_train.append(0)\n",
        "        else:\n",
        "            y_pred_all_train.append(2)\n",
        "    else:\n",
        "        y_pred_all_train.append(3)\n",
        "\n",
        "for x_test in X_all_test:\n",
        "    x_test_csp1 = csp1.transform(np.array([x_test]))\n",
        "    x_test_csp2 = csp2.transform(np.array([x_test]))\n",
        "    x_test_csp3 = csp3.transform(np.array([x_test]))\n",
        "\n",
        "    if lda1.predict(x_test_csp1) == 1:\n",
        "        if lda2.predict(x_test_csp2) == 1:\n",
        "            if lda3.predict(x_test_csp3) == 1:\n",
        "                y_pred_all_test.append(1)\n",
        "            else:\n",
        "                y_pred_all_test.append(0)\n",
        "        else:\n",
        "            y_pred_all_test.append(2)\n",
        "    else:\n",
        "        y_pred_all_test.append(3)"
      ],
      "metadata": {
        "id": "FYOGVSwT-cHz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print Results**"
      ],
      "metadata": {
        "id": "SlwPbVId-6vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print confusion matrix and accuracy for Class 4 vs. Other Classes Classifier\n",
        "print(\"Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\")\n",
        "print(confusion_matrix_train1)\n",
        "print(\"Accuracy for Class 4 vs. Other Classes Classifier (Train):\", accuracy_train1)\n",
        "print(\"\\nConfusion Matrix for Class 4 vs. Other Classes Classifier (Test):\")\n",
        "print(confusion_matrix_test1)\n",
        "print(\"Accuracy for Class 4 vs. Other Classes Classifier (Test):\", accuracy_test1)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "# Print confusion matrix and accuracy for Class 3 vs. (Class 1 and 2) Classifier\n",
        "print(\"Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\")\n",
        "print(confusion_matrix_train2)\n",
        "print(\"Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train):\", accuracy_train2)\n",
        "print(\"\\nConfusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\")\n",
        "print(confusion_matrix_test2)\n",
        "print(\"Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test):\", accuracy_test2)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "# Print confusion matrix and accuracy for Class 1 vs. Class 2 Classifier\n",
        "print(\"Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\")\n",
        "print(confusion_matrix_train3)\n",
        "print(\"Accuracy for Class 1 vs. Class 2 Classifier (Train):\", accuracy_train3)\n",
        "print(\"\\nConfusion Matrix for Class 1 vs. Class 2 Classifier (Test):\")\n",
        "print(confusion_matrix_test3)\n",
        "print(\"Accuracy for Class 1 vs. Class 2 Classifier (Test):\", accuracy_test3)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "# Print accuracy for classifier 2 and 3\n",
        "print(\"Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train):\", accuracy_train2)\n",
        "print(\"Accuracy for Class 1 vs. Class 2 Classifier (Train):\", accuracy_train3)\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "# Print confusion matrix and accuracy for the cascade of classifiers\n",
        "print(\"Confusion Matrix for the Cascade of Classifiers (Train):\")\n",
        "print(confusion_matrix(y_all_train, y_pred_all_train))\n",
        "print(\"Accuracy for the Cascade of Classifiers (Train):\", accuracy_score(y_all_train, y_pred_all_train))\n",
        "print(\"\\nConfusion Matrix for the Cascade of Classifiers (Test):\")\n",
        "print(confusion_matrix(y_all_test, y_pred_all_test))\n",
        "print(\"Accuracy for the Cascade of Classifiers (Test):\", accuracy_score(y_all_test, y_pred_all_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v68VStMI-58r",
        "outputId": "fad45b9e-3814-4d8d-c19d-677f34e05b19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 4176  8064]\n",
            " [ 1728 34992]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.8\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[ 87 168]\n",
            " [ 36 729]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.8\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[ 4464  7776]\n",
            " [ 2448 22032]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.7215686274509804\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[ 93 162]\n",
            " [ 51 459]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 0.7215686274509804\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[8544 3696]\n",
            " [4224 8016]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 0.6764705882352942\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[178  77]\n",
            " [ 88 167]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 0.6764705882352942\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.7215686274509804\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 0.6764705882352942\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[7248 3024 1248  720]\n",
            " [3648 6864 1200  528]\n",
            " [3696 3792 4272  480]\n",
            " [3648 3264 1152 4176]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.46078431372549017\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[151  63  26  15]\n",
            " [ 76 143  25  11]\n",
            " [ 77  79  89  10]\n",
            " [ 76  68  24  87]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.46078431372549017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print W(CSP) and W(LDA):\n",
        "\n",
        "# Retrieve the weights for CSP\n",
        "csp1_weights = csp1.filters_\n",
        "csp2_weights = csp1.filters_\n",
        "csp3_weights = csp1.filters_\n",
        "\n",
        "# Retrieve the weights for LDA\n",
        "lda1_weights = lda1.coef_\n",
        "lda2_weights = lda1.coef_\n",
        "lda3_weights = lda1.coef_\n",
        "\n",
        "# Print the weights for CSP\n",
        "print(\"CSP weights:\")\n",
        "print(csp1_weights)\n",
        "print(\"----\")\n",
        "print(csp2_weights)\n",
        "print(\"----\")\n",
        "print(csp3_weights)\n",
        "print(\"----\")\n",
        "\n",
        "# Print the weights for LDA\n",
        "print(\"LDA weights:\")\n",
        "print(lda1_weights)\n",
        "print(\"----\")\n",
        "print(lda2_weights)\n",
        "print(\"----\")\n",
        "print(lda3_weights)\n",
        "print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dYVP1BUBtJv",
        "outputId": "ebf0e83f-bfe4-4572-d189-2a5996eca337"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSP weights:\n",
            "[[-1.66183658e+01 -5.89211187e+00  5.83679083e+01 -1.43195597e+01\n",
            "  -8.29519263e+01  3.28855924e+01  5.97667150e+01 -2.51200090e+01\n",
            "  -4.65715597e+01 -3.29341973e+01  4.17557599e+01  5.39644241e+01\n",
            "  -1.71743784e+01  1.38427959e+02 -2.20213326e+01 -6.14022125e+02\n",
            "   3.91632108e+01  6.87207714e+02  4.39732163e-02 -2.20228902e+02\n",
            "  -1.37292774e+01]\n",
            " [-2.37900324e+00 -4.61097337e+01  3.90713188e+00  2.84551397e+02\n",
            "  -2.43555886e+01 -3.73167681e+02  1.96971867e+01  3.73048782e+02\n",
            "   8.32339003e+01 -5.49895505e+02 -7.31205529e+01  5.78532430e+02\n",
            "  -1.10761336e+01 -3.26700482e+02 -1.04834681e+02  1.02914589e+02\n",
            "   1.14788071e+01 -4.12959541e+01  2.74633186e+02  3.20890661e-01\n",
            "  -1.79443751e+02]\n",
            " [-4.12830597e+02 -2.03679932e+02  1.24690092e+03  1.36665960e+02\n",
            "  -1.23136371e+03  2.18225455e+02  3.15013941e+02 -5.19752091e+02\n",
            "   3.48450844e+02  1.60677818e+02 -1.34330410e+02  8.69867091e+02\n",
            "  -4.46842090e+02 -7.87826182e+02  1.09887695e+03  7.94688016e+01\n",
            "  -1.21664190e+03  3.66141888e+01  3.76946838e+02  3.38984181e-01\n",
            "   6.52224289e+01]\n",
            " [-5.23711042e+02 -6.88269600e+02  1.37955358e+03  1.62909857e+03\n",
            "  -1.38944555e+03 -8.79368070e+02  1.01779254e+03 -1.12251966e+03\n",
            "  -7.87338038e+02  1.07431647e+03 -4.74768850e+02  1.66732216e+03\n",
            "   5.43207839e+02 -2.43268482e+03  4.81636792e+02  1.22588671e+03\n",
            "   1.26779821e+03 -4.74510693e+02 -2.48331002e+03  2.50968903e-01\n",
            "   9.69064744e+02]\n",
            " [-1.47924048e+02 -1.29063785e+03 -8.28932311e+01  2.17449699e+03\n",
            "   1.33324492e+03 -4.73901980e+02 -1.52875225e+03 -1.41696772e+03\n",
            "   1.58649312e+02  2.19895356e+03  1.30043703e+03 -1.51798509e+03\n",
            "  -1.78286515e+03 -1.46159727e+02  7.91499845e+02  9.59337729e+02\n",
            "   2.02540914e+03 -4.94506373e+02 -3.34973302e+03 -9.02109792e-01\n",
            "   1.29119877e+03]\n",
            " [-3.56159482e+02  1.14507816e+03  1.17796702e+03 -1.45019773e+03\n",
            "  -7.01014827e+02  1.53083479e+02 -7.50186140e+02 -3.15672105e+01\n",
            "   4.84448171e+02 -5.26429653e+02  1.75744314e+03  8.15117675e+02\n",
            "  -1.95331924e+03  5.99339544e+02 -1.02988602e+03 -1.32891673e+03\n",
            "   2.78050815e+03  6.51544024e+02 -1.35081893e+03  4.74062267e-01\n",
            "  -8.65007280e+01]\n",
            " [-1.08517848e+02 -6.55442156e+02 -1.57653674e+02  1.05565065e+03\n",
            "   1.03598120e+03 -3.67538910e+01 -9.02213898e+02 -9.80379484e+02\n",
            "  -1.02735010e+03  1.25811449e+01  3.50754685e+03  3.88454473e+02\n",
            "  -3.65821141e+03  8.54244649e+02  2.52488612e+03 -1.23935936e+03\n",
            "   2.61957830e+02  5.83831624e+02 -3.02282364e+03  5.73209501e-01\n",
            "   1.56299190e+03]\n",
            " [ 1.51243484e+02 -7.00835632e+02 -6.85018031e+02  2.97520929e+03\n",
            "   1.39278847e+03 -3.64561595e+03 -1.55502104e+03  2.35378918e+03\n",
            "   2.82447600e+03 -9.66501384e+01 -2.94961145e+03 -9.70901692e+02\n",
            "   3.96435484e+02 -3.30695696e+02  6.77657264e+02  7.83890292e+02\n",
            "  -5.28406250e+02 -3.58031441e+02  8.58520867e+02 -7.34770286e-01\n",
            "  -5.92485462e+02]\n",
            " [-1.11686521e+03 -3.73156420e+02  3.96725417e+03  1.14415965e+03\n",
            "  -5.08654125e+03 -1.50192225e+03  2.62616685e+03  3.13379078e+03\n",
            "  -9.91569927e+02 -4.28658365e+03  1.53509763e+03  2.04420605e+03\n",
            "  -1.77797035e+03  1.17459458e+02  2.93131614e+03 -5.48906159e+02\n",
            "  -3.34665841e+03  2.66149199e+02  1.48478782e+03  9.19204199e-02\n",
            "  -2.20305959e+02]\n",
            " [-9.78591358e+02  4.28223812e+02  2.58755875e+03 -8.26590139e+02\n",
            "  -9.63449342e+02  4.66732389e+02 -1.81982975e+03 -2.27669712e+02\n",
            "   2.33412633e+03  1.06695866e+03 -1.31062481e+03 -1.82285019e+03\n",
            "   1.83778101e+01  9.44019523e+02  1.12527445e+03  1.29256002e+02\n",
            "  -2.06604706e+03 -1.46951758e+02  1.57849937e+03  3.88699677e-01\n",
            "  -5.16813375e+02]\n",
            " [ 1.03993118e+02  1.07432885e+03  1.74612613e+02 -3.00317834e+03\n",
            "  -5.86435513e+02  2.29200225e+03 -2.05528580e+02 -6.71075105e+02\n",
            "   2.09571614e+03  3.13559818e+02 -2.31052722e+03  7.12338486e+02\n",
            "   7.35209579e+02 -1.02690940e+03 -4.57242728e+02  4.16394337e+02\n",
            "   2.88723365e+03 -1.22152257e+02 -4.51460796e+03 -5.31369072e-02\n",
            "   2.09231836e+03]\n",
            " [ 5.65308058e+01 -1.06009980e+03  1.45240225e+02  3.34797418e+03\n",
            "  -3.83061447e+02 -2.92081932e+03 -5.11116961e+01 -1.65870270e+03\n",
            "  -4.83811632e+02  5.51556578e+03  2.59454499e+03 -4.22648982e+03\n",
            "  -2.37455307e+03  1.02212522e+03  1.84766703e+03 -9.56295073e+01\n",
            "  -2.76099197e+03  6.73799838e+01  1.58917007e+03 -2.62405345e-01\n",
            "  -1.70668548e+02]\n",
            " [-4.52355544e+02 -5.86872450e+02  2.59299686e+02  1.23729032e+03\n",
            "   1.93886215e+03 -8.01875030e+02 -2.15989042e+03  7.32337048e+00\n",
            "  -8.20456479e+02 -3.52769450e+02  1.33959304e+03  1.71810295e+03\n",
            "   1.21106929e+03 -1.49585537e+03 -4.02796171e+03  2.65154130e+02\n",
            "   3.22809210e+03 -1.02391132e+00 -1.62355079e+02  7.30573391e-03\n",
            "  -3.43379030e+02]\n",
            " [ 6.87382216e+02 -8.98699465e+02 -1.62468754e+03  1.75140642e+03\n",
            "   1.24698952e+02 -9.15035346e+02  1.82833848e+03  7.62600058e+02\n",
            "  -2.57908170e+03 -1.62226405e+02  2.19161676e+03 -3.49749197e+03\n",
            "  -4.39349145e+02  4.17097040e+03 -9.37235193e+02 -1.94345359e+03\n",
            "   1.36958405e+03  7.21132873e+02 -9.92550572e+02  1.55848896e-01\n",
            "   3.81928641e+02]\n",
            " [ 3.81502873e+02  4.28272646e+02 -2.45185015e+03 -3.31316287e+02\n",
            "   5.04837572e+03 -7.50798549e+02 -3.56268012e+03  1.69132173e+03\n",
            "   7.56890101e+02 -6.78630753e+02 -1.68730250e+03 -1.84515331e+03\n",
            "   1.89412554e+03  2.20064425e+03  1.40812570e+03 -1.25167637e+03\n",
            "  -2.73450302e+03  5.37789614e+02  5.41613142e+02 -8.32348219e-01\n",
            "   4.06082102e+02]\n",
            " [ 4.01610997e+02  8.72447140e+02 -1.10702226e+03 -9.41385056e+02\n",
            "   3.38350831e+02 -1.15902825e+03  1.42700066e+03  3.14787267e+03\n",
            "  -4.48923700e+03 -1.78721884e+03  5.99592209e+03  6.59140321e+02\n",
            "  -2.98831135e+03 -1.67864621e+03  4.14076442e+02  1.58830718e+03\n",
            "   8.15271972e+02 -6.95962851e+02 -1.32775290e+03 -2.33978159e-01\n",
            "   5.14798471e+02]\n",
            " [ 6.89461976e+00  7.22534837e+02 -4.01077600e+02 -3.13708292e+03\n",
            "   1.46044939e+03  3.89743944e+03 -1.42033705e+03 -2.95914479e+03\n",
            "  -9.30328088e+02  1.31481053e+03  3.22552232e+03  1.18483105e+03\n",
            "  -2.48167134e+03 -1.55413430e+03  2.37369519e+03  9.44898891e+02\n",
            "  -4.32242718e+03 -4.11853792e+02  3.63218761e+03 -6.23537435e-01\n",
            "  -1.14458361e+03]\n",
            " [-2.32750782e+02  4.44579201e+02 -4.15490794e+01 -1.34768874e+03\n",
            "   2.02048595e+03  6.22165107e+02 -2.86736777e+03  2.24124570e+03\n",
            "   1.78442907e+03 -1.52660840e+03  6.59978587e+02 -2.56433482e+03\n",
            "  -1.84595835e+03  2.50674407e+03 -4.31392862e+02 -4.30120063e+02\n",
            "   2.22354785e+03  5.14490860e+01 -1.52961734e+03  1.49659528e-01\n",
            "   2.62611050e+02]\n",
            " [-1.18558764e+03  5.08302164e+02  3.98592416e+03 -1.28569902e+03\n",
            "  -4.78401435e+03  1.13322337e+03  2.61923324e+03 -1.46956682e+03\n",
            "  -1.94339895e+03  3.46404377e+03  4.10681055e+02 -4.47371044e+03\n",
            "   1.93971916e+03  2.46564606e+03 -2.30696581e+03 -3.91311476e+02\n",
            "   1.86570167e+03  5.94880063e+01 -6.27342139e+02  1.13664763e-01\n",
            "   1.55152488e+01]\n",
            " [-4.29081266e+02 -1.49169358e+03  1.70969423e+03  3.26853326e+03\n",
            "  -1.55828826e+03 -2.27560408e+03 -5.20580415e+02  1.97151734e+03\n",
            "   1.49759660e+03 -2.92934535e+03 -9.83794370e+02  2.11678745e+03\n",
            "   1.05516956e+03 -9.40284987e+02 -1.45911208e+03  5.06529466e+02\n",
            "   9.89212037e+02 -2.46423338e+02 -1.02464203e+03 -2.90697406e-01\n",
            "   7.44101322e+02]\n",
            " [ 1.37294267e+02 -6.27635465e+02 -7.27560079e+02  1.89429953e+03\n",
            "   1.44275243e+03 -1.38716333e+03 -9.64395165e+02  1.05632116e+03\n",
            "  -5.36862481e+02 -3.33033074e+03  9.34843076e+02  3.88360561e+03\n",
            "  -2.47759201e+02 -1.68819333e+03  7.04606350e+01  4.13305153e+02\n",
            "  -3.30290091e+01 -2.01281221e+02 -3.91731211e+01  2.01815823e-01\n",
            "  -4.97041879e+01]]\n",
            "----\n",
            "[[-1.66183658e+01 -5.89211187e+00  5.83679083e+01 -1.43195597e+01\n",
            "  -8.29519263e+01  3.28855924e+01  5.97667150e+01 -2.51200090e+01\n",
            "  -4.65715597e+01 -3.29341973e+01  4.17557599e+01  5.39644241e+01\n",
            "  -1.71743784e+01  1.38427959e+02 -2.20213326e+01 -6.14022125e+02\n",
            "   3.91632108e+01  6.87207714e+02  4.39732163e-02 -2.20228902e+02\n",
            "  -1.37292774e+01]\n",
            " [-2.37900324e+00 -4.61097337e+01  3.90713188e+00  2.84551397e+02\n",
            "  -2.43555886e+01 -3.73167681e+02  1.96971867e+01  3.73048782e+02\n",
            "   8.32339003e+01 -5.49895505e+02 -7.31205529e+01  5.78532430e+02\n",
            "  -1.10761336e+01 -3.26700482e+02 -1.04834681e+02  1.02914589e+02\n",
            "   1.14788071e+01 -4.12959541e+01  2.74633186e+02  3.20890661e-01\n",
            "  -1.79443751e+02]\n",
            " [-4.12830597e+02 -2.03679932e+02  1.24690092e+03  1.36665960e+02\n",
            "  -1.23136371e+03  2.18225455e+02  3.15013941e+02 -5.19752091e+02\n",
            "   3.48450844e+02  1.60677818e+02 -1.34330410e+02  8.69867091e+02\n",
            "  -4.46842090e+02 -7.87826182e+02  1.09887695e+03  7.94688016e+01\n",
            "  -1.21664190e+03  3.66141888e+01  3.76946838e+02  3.38984181e-01\n",
            "   6.52224289e+01]\n",
            " [-5.23711042e+02 -6.88269600e+02  1.37955358e+03  1.62909857e+03\n",
            "  -1.38944555e+03 -8.79368070e+02  1.01779254e+03 -1.12251966e+03\n",
            "  -7.87338038e+02  1.07431647e+03 -4.74768850e+02  1.66732216e+03\n",
            "   5.43207839e+02 -2.43268482e+03  4.81636792e+02  1.22588671e+03\n",
            "   1.26779821e+03 -4.74510693e+02 -2.48331002e+03  2.50968903e-01\n",
            "   9.69064744e+02]\n",
            " [-1.47924048e+02 -1.29063785e+03 -8.28932311e+01  2.17449699e+03\n",
            "   1.33324492e+03 -4.73901980e+02 -1.52875225e+03 -1.41696772e+03\n",
            "   1.58649312e+02  2.19895356e+03  1.30043703e+03 -1.51798509e+03\n",
            "  -1.78286515e+03 -1.46159727e+02  7.91499845e+02  9.59337729e+02\n",
            "   2.02540914e+03 -4.94506373e+02 -3.34973302e+03 -9.02109792e-01\n",
            "   1.29119877e+03]\n",
            " [-3.56159482e+02  1.14507816e+03  1.17796702e+03 -1.45019773e+03\n",
            "  -7.01014827e+02  1.53083479e+02 -7.50186140e+02 -3.15672105e+01\n",
            "   4.84448171e+02 -5.26429653e+02  1.75744314e+03  8.15117675e+02\n",
            "  -1.95331924e+03  5.99339544e+02 -1.02988602e+03 -1.32891673e+03\n",
            "   2.78050815e+03  6.51544024e+02 -1.35081893e+03  4.74062267e-01\n",
            "  -8.65007280e+01]\n",
            " [-1.08517848e+02 -6.55442156e+02 -1.57653674e+02  1.05565065e+03\n",
            "   1.03598120e+03 -3.67538910e+01 -9.02213898e+02 -9.80379484e+02\n",
            "  -1.02735010e+03  1.25811449e+01  3.50754685e+03  3.88454473e+02\n",
            "  -3.65821141e+03  8.54244649e+02  2.52488612e+03 -1.23935936e+03\n",
            "   2.61957830e+02  5.83831624e+02 -3.02282364e+03  5.73209501e-01\n",
            "   1.56299190e+03]\n",
            " [ 1.51243484e+02 -7.00835632e+02 -6.85018031e+02  2.97520929e+03\n",
            "   1.39278847e+03 -3.64561595e+03 -1.55502104e+03  2.35378918e+03\n",
            "   2.82447600e+03 -9.66501384e+01 -2.94961145e+03 -9.70901692e+02\n",
            "   3.96435484e+02 -3.30695696e+02  6.77657264e+02  7.83890292e+02\n",
            "  -5.28406250e+02 -3.58031441e+02  8.58520867e+02 -7.34770286e-01\n",
            "  -5.92485462e+02]\n",
            " [-1.11686521e+03 -3.73156420e+02  3.96725417e+03  1.14415965e+03\n",
            "  -5.08654125e+03 -1.50192225e+03  2.62616685e+03  3.13379078e+03\n",
            "  -9.91569927e+02 -4.28658365e+03  1.53509763e+03  2.04420605e+03\n",
            "  -1.77797035e+03  1.17459458e+02  2.93131614e+03 -5.48906159e+02\n",
            "  -3.34665841e+03  2.66149199e+02  1.48478782e+03  9.19204199e-02\n",
            "  -2.20305959e+02]\n",
            " [-9.78591358e+02  4.28223812e+02  2.58755875e+03 -8.26590139e+02\n",
            "  -9.63449342e+02  4.66732389e+02 -1.81982975e+03 -2.27669712e+02\n",
            "   2.33412633e+03  1.06695866e+03 -1.31062481e+03 -1.82285019e+03\n",
            "   1.83778101e+01  9.44019523e+02  1.12527445e+03  1.29256002e+02\n",
            "  -2.06604706e+03 -1.46951758e+02  1.57849937e+03  3.88699677e-01\n",
            "  -5.16813375e+02]\n",
            " [ 1.03993118e+02  1.07432885e+03  1.74612613e+02 -3.00317834e+03\n",
            "  -5.86435513e+02  2.29200225e+03 -2.05528580e+02 -6.71075105e+02\n",
            "   2.09571614e+03  3.13559818e+02 -2.31052722e+03  7.12338486e+02\n",
            "   7.35209579e+02 -1.02690940e+03 -4.57242728e+02  4.16394337e+02\n",
            "   2.88723365e+03 -1.22152257e+02 -4.51460796e+03 -5.31369072e-02\n",
            "   2.09231836e+03]\n",
            " [ 5.65308058e+01 -1.06009980e+03  1.45240225e+02  3.34797418e+03\n",
            "  -3.83061447e+02 -2.92081932e+03 -5.11116961e+01 -1.65870270e+03\n",
            "  -4.83811632e+02  5.51556578e+03  2.59454499e+03 -4.22648982e+03\n",
            "  -2.37455307e+03  1.02212522e+03  1.84766703e+03 -9.56295073e+01\n",
            "  -2.76099197e+03  6.73799838e+01  1.58917007e+03 -2.62405345e-01\n",
            "  -1.70668548e+02]\n",
            " [-4.52355544e+02 -5.86872450e+02  2.59299686e+02  1.23729032e+03\n",
            "   1.93886215e+03 -8.01875030e+02 -2.15989042e+03  7.32337048e+00\n",
            "  -8.20456479e+02 -3.52769450e+02  1.33959304e+03  1.71810295e+03\n",
            "   1.21106929e+03 -1.49585537e+03 -4.02796171e+03  2.65154130e+02\n",
            "   3.22809210e+03 -1.02391132e+00 -1.62355079e+02  7.30573391e-03\n",
            "  -3.43379030e+02]\n",
            " [ 6.87382216e+02 -8.98699465e+02 -1.62468754e+03  1.75140642e+03\n",
            "   1.24698952e+02 -9.15035346e+02  1.82833848e+03  7.62600058e+02\n",
            "  -2.57908170e+03 -1.62226405e+02  2.19161676e+03 -3.49749197e+03\n",
            "  -4.39349145e+02  4.17097040e+03 -9.37235193e+02 -1.94345359e+03\n",
            "   1.36958405e+03  7.21132873e+02 -9.92550572e+02  1.55848896e-01\n",
            "   3.81928641e+02]\n",
            " [ 3.81502873e+02  4.28272646e+02 -2.45185015e+03 -3.31316287e+02\n",
            "   5.04837572e+03 -7.50798549e+02 -3.56268012e+03  1.69132173e+03\n",
            "   7.56890101e+02 -6.78630753e+02 -1.68730250e+03 -1.84515331e+03\n",
            "   1.89412554e+03  2.20064425e+03  1.40812570e+03 -1.25167637e+03\n",
            "  -2.73450302e+03  5.37789614e+02  5.41613142e+02 -8.32348219e-01\n",
            "   4.06082102e+02]\n",
            " [ 4.01610997e+02  8.72447140e+02 -1.10702226e+03 -9.41385056e+02\n",
            "   3.38350831e+02 -1.15902825e+03  1.42700066e+03  3.14787267e+03\n",
            "  -4.48923700e+03 -1.78721884e+03  5.99592209e+03  6.59140321e+02\n",
            "  -2.98831135e+03 -1.67864621e+03  4.14076442e+02  1.58830718e+03\n",
            "   8.15271972e+02 -6.95962851e+02 -1.32775290e+03 -2.33978159e-01\n",
            "   5.14798471e+02]\n",
            " [ 6.89461976e+00  7.22534837e+02 -4.01077600e+02 -3.13708292e+03\n",
            "   1.46044939e+03  3.89743944e+03 -1.42033705e+03 -2.95914479e+03\n",
            "  -9.30328088e+02  1.31481053e+03  3.22552232e+03  1.18483105e+03\n",
            "  -2.48167134e+03 -1.55413430e+03  2.37369519e+03  9.44898891e+02\n",
            "  -4.32242718e+03 -4.11853792e+02  3.63218761e+03 -6.23537435e-01\n",
            "  -1.14458361e+03]\n",
            " [-2.32750782e+02  4.44579201e+02 -4.15490794e+01 -1.34768874e+03\n",
            "   2.02048595e+03  6.22165107e+02 -2.86736777e+03  2.24124570e+03\n",
            "   1.78442907e+03 -1.52660840e+03  6.59978587e+02 -2.56433482e+03\n",
            "  -1.84595835e+03  2.50674407e+03 -4.31392862e+02 -4.30120063e+02\n",
            "   2.22354785e+03  5.14490860e+01 -1.52961734e+03  1.49659528e-01\n",
            "   2.62611050e+02]\n",
            " [-1.18558764e+03  5.08302164e+02  3.98592416e+03 -1.28569902e+03\n",
            "  -4.78401435e+03  1.13322337e+03  2.61923324e+03 -1.46956682e+03\n",
            "  -1.94339895e+03  3.46404377e+03  4.10681055e+02 -4.47371044e+03\n",
            "   1.93971916e+03  2.46564606e+03 -2.30696581e+03 -3.91311476e+02\n",
            "   1.86570167e+03  5.94880063e+01 -6.27342139e+02  1.13664763e-01\n",
            "   1.55152488e+01]\n",
            " [-4.29081266e+02 -1.49169358e+03  1.70969423e+03  3.26853326e+03\n",
            "  -1.55828826e+03 -2.27560408e+03 -5.20580415e+02  1.97151734e+03\n",
            "   1.49759660e+03 -2.92934535e+03 -9.83794370e+02  2.11678745e+03\n",
            "   1.05516956e+03 -9.40284987e+02 -1.45911208e+03  5.06529466e+02\n",
            "   9.89212037e+02 -2.46423338e+02 -1.02464203e+03 -2.90697406e-01\n",
            "   7.44101322e+02]\n",
            " [ 1.37294267e+02 -6.27635465e+02 -7.27560079e+02  1.89429953e+03\n",
            "   1.44275243e+03 -1.38716333e+03 -9.64395165e+02  1.05632116e+03\n",
            "  -5.36862481e+02 -3.33033074e+03  9.34843076e+02  3.88360561e+03\n",
            "  -2.47759201e+02 -1.68819333e+03  7.04606350e+01  4.13305153e+02\n",
            "  -3.30290091e+01 -2.01281221e+02 -3.91731211e+01  2.01815823e-01\n",
            "  -4.97041879e+01]]\n",
            "----\n",
            "[[-1.66183658e+01 -5.89211187e+00  5.83679083e+01 -1.43195597e+01\n",
            "  -8.29519263e+01  3.28855924e+01  5.97667150e+01 -2.51200090e+01\n",
            "  -4.65715597e+01 -3.29341973e+01  4.17557599e+01  5.39644241e+01\n",
            "  -1.71743784e+01  1.38427959e+02 -2.20213326e+01 -6.14022125e+02\n",
            "   3.91632108e+01  6.87207714e+02  4.39732163e-02 -2.20228902e+02\n",
            "  -1.37292774e+01]\n",
            " [-2.37900324e+00 -4.61097337e+01  3.90713188e+00  2.84551397e+02\n",
            "  -2.43555886e+01 -3.73167681e+02  1.96971867e+01  3.73048782e+02\n",
            "   8.32339003e+01 -5.49895505e+02 -7.31205529e+01  5.78532430e+02\n",
            "  -1.10761336e+01 -3.26700482e+02 -1.04834681e+02  1.02914589e+02\n",
            "   1.14788071e+01 -4.12959541e+01  2.74633186e+02  3.20890661e-01\n",
            "  -1.79443751e+02]\n",
            " [-4.12830597e+02 -2.03679932e+02  1.24690092e+03  1.36665960e+02\n",
            "  -1.23136371e+03  2.18225455e+02  3.15013941e+02 -5.19752091e+02\n",
            "   3.48450844e+02  1.60677818e+02 -1.34330410e+02  8.69867091e+02\n",
            "  -4.46842090e+02 -7.87826182e+02  1.09887695e+03  7.94688016e+01\n",
            "  -1.21664190e+03  3.66141888e+01  3.76946838e+02  3.38984181e-01\n",
            "   6.52224289e+01]\n",
            " [-5.23711042e+02 -6.88269600e+02  1.37955358e+03  1.62909857e+03\n",
            "  -1.38944555e+03 -8.79368070e+02  1.01779254e+03 -1.12251966e+03\n",
            "  -7.87338038e+02  1.07431647e+03 -4.74768850e+02  1.66732216e+03\n",
            "   5.43207839e+02 -2.43268482e+03  4.81636792e+02  1.22588671e+03\n",
            "   1.26779821e+03 -4.74510693e+02 -2.48331002e+03  2.50968903e-01\n",
            "   9.69064744e+02]\n",
            " [-1.47924048e+02 -1.29063785e+03 -8.28932311e+01  2.17449699e+03\n",
            "   1.33324492e+03 -4.73901980e+02 -1.52875225e+03 -1.41696772e+03\n",
            "   1.58649312e+02  2.19895356e+03  1.30043703e+03 -1.51798509e+03\n",
            "  -1.78286515e+03 -1.46159727e+02  7.91499845e+02  9.59337729e+02\n",
            "   2.02540914e+03 -4.94506373e+02 -3.34973302e+03 -9.02109792e-01\n",
            "   1.29119877e+03]\n",
            " [-3.56159482e+02  1.14507816e+03  1.17796702e+03 -1.45019773e+03\n",
            "  -7.01014827e+02  1.53083479e+02 -7.50186140e+02 -3.15672105e+01\n",
            "   4.84448171e+02 -5.26429653e+02  1.75744314e+03  8.15117675e+02\n",
            "  -1.95331924e+03  5.99339544e+02 -1.02988602e+03 -1.32891673e+03\n",
            "   2.78050815e+03  6.51544024e+02 -1.35081893e+03  4.74062267e-01\n",
            "  -8.65007280e+01]\n",
            " [-1.08517848e+02 -6.55442156e+02 -1.57653674e+02  1.05565065e+03\n",
            "   1.03598120e+03 -3.67538910e+01 -9.02213898e+02 -9.80379484e+02\n",
            "  -1.02735010e+03  1.25811449e+01  3.50754685e+03  3.88454473e+02\n",
            "  -3.65821141e+03  8.54244649e+02  2.52488612e+03 -1.23935936e+03\n",
            "   2.61957830e+02  5.83831624e+02 -3.02282364e+03  5.73209501e-01\n",
            "   1.56299190e+03]\n",
            " [ 1.51243484e+02 -7.00835632e+02 -6.85018031e+02  2.97520929e+03\n",
            "   1.39278847e+03 -3.64561595e+03 -1.55502104e+03  2.35378918e+03\n",
            "   2.82447600e+03 -9.66501384e+01 -2.94961145e+03 -9.70901692e+02\n",
            "   3.96435484e+02 -3.30695696e+02  6.77657264e+02  7.83890292e+02\n",
            "  -5.28406250e+02 -3.58031441e+02  8.58520867e+02 -7.34770286e-01\n",
            "  -5.92485462e+02]\n",
            " [-1.11686521e+03 -3.73156420e+02  3.96725417e+03  1.14415965e+03\n",
            "  -5.08654125e+03 -1.50192225e+03  2.62616685e+03  3.13379078e+03\n",
            "  -9.91569927e+02 -4.28658365e+03  1.53509763e+03  2.04420605e+03\n",
            "  -1.77797035e+03  1.17459458e+02  2.93131614e+03 -5.48906159e+02\n",
            "  -3.34665841e+03  2.66149199e+02  1.48478782e+03  9.19204199e-02\n",
            "  -2.20305959e+02]\n",
            " [-9.78591358e+02  4.28223812e+02  2.58755875e+03 -8.26590139e+02\n",
            "  -9.63449342e+02  4.66732389e+02 -1.81982975e+03 -2.27669712e+02\n",
            "   2.33412633e+03  1.06695866e+03 -1.31062481e+03 -1.82285019e+03\n",
            "   1.83778101e+01  9.44019523e+02  1.12527445e+03  1.29256002e+02\n",
            "  -2.06604706e+03 -1.46951758e+02  1.57849937e+03  3.88699677e-01\n",
            "  -5.16813375e+02]\n",
            " [ 1.03993118e+02  1.07432885e+03  1.74612613e+02 -3.00317834e+03\n",
            "  -5.86435513e+02  2.29200225e+03 -2.05528580e+02 -6.71075105e+02\n",
            "   2.09571614e+03  3.13559818e+02 -2.31052722e+03  7.12338486e+02\n",
            "   7.35209579e+02 -1.02690940e+03 -4.57242728e+02  4.16394337e+02\n",
            "   2.88723365e+03 -1.22152257e+02 -4.51460796e+03 -5.31369072e-02\n",
            "   2.09231836e+03]\n",
            " [ 5.65308058e+01 -1.06009980e+03  1.45240225e+02  3.34797418e+03\n",
            "  -3.83061447e+02 -2.92081932e+03 -5.11116961e+01 -1.65870270e+03\n",
            "  -4.83811632e+02  5.51556578e+03  2.59454499e+03 -4.22648982e+03\n",
            "  -2.37455307e+03  1.02212522e+03  1.84766703e+03 -9.56295073e+01\n",
            "  -2.76099197e+03  6.73799838e+01  1.58917007e+03 -2.62405345e-01\n",
            "  -1.70668548e+02]\n",
            " [-4.52355544e+02 -5.86872450e+02  2.59299686e+02  1.23729032e+03\n",
            "   1.93886215e+03 -8.01875030e+02 -2.15989042e+03  7.32337048e+00\n",
            "  -8.20456479e+02 -3.52769450e+02  1.33959304e+03  1.71810295e+03\n",
            "   1.21106929e+03 -1.49585537e+03 -4.02796171e+03  2.65154130e+02\n",
            "   3.22809210e+03 -1.02391132e+00 -1.62355079e+02  7.30573391e-03\n",
            "  -3.43379030e+02]\n",
            " [ 6.87382216e+02 -8.98699465e+02 -1.62468754e+03  1.75140642e+03\n",
            "   1.24698952e+02 -9.15035346e+02  1.82833848e+03  7.62600058e+02\n",
            "  -2.57908170e+03 -1.62226405e+02  2.19161676e+03 -3.49749197e+03\n",
            "  -4.39349145e+02  4.17097040e+03 -9.37235193e+02 -1.94345359e+03\n",
            "   1.36958405e+03  7.21132873e+02 -9.92550572e+02  1.55848896e-01\n",
            "   3.81928641e+02]\n",
            " [ 3.81502873e+02  4.28272646e+02 -2.45185015e+03 -3.31316287e+02\n",
            "   5.04837572e+03 -7.50798549e+02 -3.56268012e+03  1.69132173e+03\n",
            "   7.56890101e+02 -6.78630753e+02 -1.68730250e+03 -1.84515331e+03\n",
            "   1.89412554e+03  2.20064425e+03  1.40812570e+03 -1.25167637e+03\n",
            "  -2.73450302e+03  5.37789614e+02  5.41613142e+02 -8.32348219e-01\n",
            "   4.06082102e+02]\n",
            " [ 4.01610997e+02  8.72447140e+02 -1.10702226e+03 -9.41385056e+02\n",
            "   3.38350831e+02 -1.15902825e+03  1.42700066e+03  3.14787267e+03\n",
            "  -4.48923700e+03 -1.78721884e+03  5.99592209e+03  6.59140321e+02\n",
            "  -2.98831135e+03 -1.67864621e+03  4.14076442e+02  1.58830718e+03\n",
            "   8.15271972e+02 -6.95962851e+02 -1.32775290e+03 -2.33978159e-01\n",
            "   5.14798471e+02]\n",
            " [ 6.89461976e+00  7.22534837e+02 -4.01077600e+02 -3.13708292e+03\n",
            "   1.46044939e+03  3.89743944e+03 -1.42033705e+03 -2.95914479e+03\n",
            "  -9.30328088e+02  1.31481053e+03  3.22552232e+03  1.18483105e+03\n",
            "  -2.48167134e+03 -1.55413430e+03  2.37369519e+03  9.44898891e+02\n",
            "  -4.32242718e+03 -4.11853792e+02  3.63218761e+03 -6.23537435e-01\n",
            "  -1.14458361e+03]\n",
            " [-2.32750782e+02  4.44579201e+02 -4.15490794e+01 -1.34768874e+03\n",
            "   2.02048595e+03  6.22165107e+02 -2.86736777e+03  2.24124570e+03\n",
            "   1.78442907e+03 -1.52660840e+03  6.59978587e+02 -2.56433482e+03\n",
            "  -1.84595835e+03  2.50674407e+03 -4.31392862e+02 -4.30120063e+02\n",
            "   2.22354785e+03  5.14490860e+01 -1.52961734e+03  1.49659528e-01\n",
            "   2.62611050e+02]\n",
            " [-1.18558764e+03  5.08302164e+02  3.98592416e+03 -1.28569902e+03\n",
            "  -4.78401435e+03  1.13322337e+03  2.61923324e+03 -1.46956682e+03\n",
            "  -1.94339895e+03  3.46404377e+03  4.10681055e+02 -4.47371044e+03\n",
            "   1.93971916e+03  2.46564606e+03 -2.30696581e+03 -3.91311476e+02\n",
            "   1.86570167e+03  5.94880063e+01 -6.27342139e+02  1.13664763e-01\n",
            "   1.55152488e+01]\n",
            " [-4.29081266e+02 -1.49169358e+03  1.70969423e+03  3.26853326e+03\n",
            "  -1.55828826e+03 -2.27560408e+03 -5.20580415e+02  1.97151734e+03\n",
            "   1.49759660e+03 -2.92934535e+03 -9.83794370e+02  2.11678745e+03\n",
            "   1.05516956e+03 -9.40284987e+02 -1.45911208e+03  5.06529466e+02\n",
            "   9.89212037e+02 -2.46423338e+02 -1.02464203e+03 -2.90697406e-01\n",
            "   7.44101322e+02]\n",
            " [ 1.37294267e+02 -6.27635465e+02 -7.27560079e+02  1.89429953e+03\n",
            "   1.44275243e+03 -1.38716333e+03 -9.64395165e+02  1.05632116e+03\n",
            "  -5.36862481e+02 -3.33033074e+03  9.34843076e+02  3.88360561e+03\n",
            "  -2.47759201e+02 -1.68819333e+03  7.04606350e+01  4.13305153e+02\n",
            "  -3.30290091e+01 -2.01281221e+02 -3.91731211e+01  2.01815823e-01\n",
            "  -4.97041879e+01]]\n",
            "----\n",
            "LDA weights:\n",
            "[[ 0.03383232 -0.27944727 -0.67284225  0.64624    -0.83215001 -0.52023732\n",
            "   0.41769603  0.46566445 -0.32903971  0.22638007 -0.312386    0.40908209\n",
            "  -0.34336758  0.15799461 -0.04598868 -0.14745114  0.13245944 -0.00182117\n",
            "  -0.00597727  0.07735385  0.08457787]]\n",
            "----\n",
            "[[ 0.03383232 -0.27944727 -0.67284225  0.64624    -0.83215001 -0.52023732\n",
            "   0.41769603  0.46566445 -0.32903971  0.22638007 -0.312386    0.40908209\n",
            "  -0.34336758  0.15799461 -0.04598868 -0.14745114  0.13245944 -0.00182117\n",
            "  -0.00597727  0.07735385  0.08457787]]\n",
            "----\n",
            "[[ 0.03383232 -0.27944727 -0.67284225  0.64624    -0.83215001 -0.52023732\n",
            "   0.41769603  0.46566445 -0.32903971  0.22638007 -0.312386    0.40908209\n",
            "  -0.34336758  0.15799461 -0.04598868 -0.14745114  0.13245944 -0.00182117\n",
            "  -0.00597727  0.07735385  0.08457787]]\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train 1 Model for ALL 15 person data  - Split Randomly\n",
        "\n",
        "Train only one model and evaluate model on unseen data ( different to last is that we dont use LOO method for split )"
      ],
      "metadata": {
        "id": "IGFHv0xxqmIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the channels of interest\n",
        "channels_of_interest = [11, 40, 12, 41, 13, 42, 14, 44, 16, 45, 17, 46, 18, 47, 20, 49, 21, 50, 22, 51, 23]\n",
        "# Initialize empty lists for X and Y data\n",
        "X = []\n",
        "Y = []\n",
        "min_num_trials = float('inf')  # Initialize with a large value\n",
        "# Loop over each person's data\n",
        "for i in range(1, 16):\n",
        "    # Load the .mat file for each person\n",
        "    data = loadmat(f'dataset/subj_{i}.mat')['data'][0]\n",
        "    # Extract the classes\n",
        "    class_1 = data[0][:, channels_of_interest, :]\n",
        "    class_2 = data[1][:, channels_of_interest, :]\n",
        "    class_3 = data[2][:, channels_of_interest, :]\n",
        "    class_4 = data[3][:, channels_of_interest, :]\n",
        "    # Determine the minimum number of trials among all classes\n",
        "    min_num_trials = min(min_num_trials, class_1.shape[2], class_2.shape[2], class_3.shape[2], class_4.shape[2])\n",
        "    # Append the data to X and Y\n",
        "    X.append(class_1[:, :, :min_num_trials])\n",
        "    X.append(class_2[:, :, :min_num_trials])\n",
        "    X.append(class_3[:, :, :min_num_trials])\n",
        "    X.append(class_4[:, :, :min_num_trials])\n",
        "    # Create labels for the classes\n",
        "    num_samples = min_num_trials * 4\n",
        "    labels = np.zeros((num_samples,))\n",
        "    labels[min_num_trials:min_num_trials * 2] = 1\n",
        "    labels[min_num_trials * 2:min_num_trials * 3] = 2\n",
        "    labels[min_num_trials * 3:] = 3\n",
        "    # Append the labels to Y\n",
        "    Y.append(labels)"
      ],
      "metadata": {
        "id": "RTc1LM_Nqu8y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate(X, axis=2)\n",
        "Y = np.concatenate(Y, axis=0)\n",
        "X = X.transpose((2, 1, 0))\n",
        "X1 = X[Y == 0]\n",
        "X2 = X[Y == 1]\n",
        "X3 = X[Y == 2]\n",
        "X4 = X[Y == 3]\n",
        "# Delete samples with NaN and inf values \n",
        "X1 = X1[np.logical_not(np.isnan(np.sum(X1, axis=(1, 2))) | np.isinf(np.sum(X1, axis=(1, 2))))]\n",
        "X2 = X2[np.logical_not(np.isnan(np.sum(X2, axis=(1, 2))) | np.isinf(np.sum(X2, axis=(1, 2))))]\n",
        "X3 = X3[np.logical_not(np.isnan(np.sum(X3, axis=(1, 2))) | np.isinf(np.sum(X3, axis=(1, 2))))]\n",
        "X4 = np.nan_to_num(X4) "
      ],
      "metadata": {
        "id": "-U18pj0UrDir"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 4 vs. Other Classes Classifier\n",
        "X_classifier1 = np.concatenate((X1, X2, X3, X4), axis=0)\n",
        "y_classifier1 = np.concatenate((np.ones(X1.shape[0]), np.ones(X2.shape[0]), np.ones(X3.shape[0]) , np.zeros(X4.shape[0])))\n",
        "\n",
        "X_classifier1_train, X_classifier1_test, y_classifier1_train, y_classifier1_test = train_test_split(\n",
        "    X_classifier1, y_classifier1, test_size=0.2, random_state=42)\n",
        "\n",
        "# Class 3 vs. (Class 1 and 2) Classifier\n",
        "X_classifier2 = np.concatenate((X3, X1, X2), axis=0)\n",
        "y_classifier2 = np.concatenate((np.zeros(X3.shape[0]), np.ones(X1.shape[0]), np.ones(X2.shape[0])))\n",
        "\n",
        "X_classifier2_train, X_classifier2_test, y_classifier2_train, y_classifier2_test = train_test_split(\n",
        "    X_classifier2, y_classifier2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Class 1 vs. Class 2 Classifier\n",
        "X_classifier3 = np.concatenate((X1, X2), axis=0)\n",
        "X_classifier3_train, X_classifier3_test, y_classifier3_train, y_classifier3_test = train_test_split(\n",
        "    np.concatenate((X1, X2), axis=0), np.concatenate((np.zeros(X1.shape[0]), np.ones(X2.shape[0]))),\n",
        "    test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply CSP to X_classifier1 train and test data\n",
        "csp1 = CSP(n_components=32, reg=None, log=True)\n",
        "X_classifier1_train_csp = csp1.fit_transform(X_classifier1_train, y_classifier1_train)\n",
        "X_classifier1_test_csp = csp1.transform(X_classifier1_test)\n",
        "\n",
        "# Apply CSP to X_classifier2 train and test data\n",
        "csp2 = CSP(n_components=32, reg=None, log=True)\n",
        "X_classifier2_train_csp = csp2.fit_transform(X_classifier2_train, y_classifier2_train)\n",
        "X_classifier2_test_csp = csp2.transform(X_classifier2_test)\n",
        "\n",
        "# Apply CSP to X_classifier3 train and test data\n",
        "csp3 = CSP(n_components=32, reg=None, log=True)\n",
        "X_classifier3_train_csp = csp3.fit_transform(X_classifier3_train, y_classifier3_train)\n",
        "X_classifier3_test_csp = csp3.transform(X_classifier3_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jal3-zyurTPL",
        "outputId": "2e115007-6235-49c8-9225-99e9fd12ae15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing rank from data with rank=None\n",
            "    Using tolerance 37 (2.2e-16 eps * 21 dim * 7.9e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 43 (2.2e-16 eps * 21 dim * 9.3e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 23 (2.2e-16 eps * 21 dim * 4.9e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 36 (2.2e-16 eps * 21 dim * 7.7e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 26 (2.2e-16 eps * 21 dim * 5.6e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 26 (2.2e-16 eps * 21 dim * 5.5e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Class 4 vs. Other Classes Classifier\n",
        "lda1 = LinearDiscriminantAnalysis()\n",
        "lda1.fit(X_classifier1_train_csp, y_classifier1_train)\n",
        "\n",
        "# Predict on train and test data\n",
        "y_classifier1_train_pred = lda1.predict(X_classifier1_train_csp)\n",
        "y_classifier1_test_pred = lda1.predict(X_classifier1_test_csp)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_train1 = accuracy_score(y_classifier1_train, y_classifier1_train_pred)\n",
        "accuracy_test1 = accuracy_score(y_classifier1_test, y_classifier1_test_pred)\n",
        "\n",
        "# Calculate confusion matrices\n",
        "confusion_matrix_train = confusion_matrix(y_classifier1_train, y_classifier1_train_pred)\n",
        "confusion_matrix_test = confusion_matrix(y_classifier1_test, y_classifier1_test_pred)\n",
        "\n",
        "print(\"Classifier 1 - Class 4 vs. Other Classes\")\n",
        "print(\"Train Accuracy:\", accuracy_train1)\n",
        "print(\"Test Accuracy:\", accuracy_test1)\n",
        "print(\"Confusion Matrix Train :\")\n",
        "print(confusion_matrix_train)\n",
        "print(\"Confusion Matrix Test :\")\n",
        "print(confusion_matrix_test)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUb7ElgHrulK",
        "outputId": "835abc15-3efa-4a03-cef8-20ca9eb9bec4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier 1 - Class 4 vs. Other Classes\n",
            "Train Accuracy: 0.8125\n",
            "Test Accuracy: 0.7647058823529411\n",
            "Confusion Matrix Train :\n",
            "[[ 80 127]\n",
            " [ 26 583]]\n",
            "Confusion Matrix Test :\n",
            "[[  9  39]\n",
            " [  9 147]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Class 3 vs. (Class 1 and 2) Classifier\n",
        "lda2 = LinearDiscriminantAnalysis()\n",
        "lda2.fit(X_classifier2_train_csp, y_classifier2_train)\n",
        "\n",
        "# Predict on train and test data\n",
        "y_classifier2_train_pred = lda2.predict(X_classifier2_train_csp)\n",
        "y_classifier2_test_pred = lda2.predict(X_classifier2_test_csp)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_train2 = accuracy_score(y_classifier2_train, y_classifier2_train_pred)\n",
        "accuracy_test2 = accuracy_score(y_classifier2_test, y_classifier2_test_pred)\n",
        "\n",
        "# Calculate confusion matrices\n",
        "confusion_matrix_train = confusion_matrix(y_classifier2_train, y_classifier2_train_pred)\n",
        "confusion_matrix_test = confusion_matrix(y_classifier2_test, y_classifier2_test_pred)\n",
        "\n",
        "print(\"Classifier 2 - Class 3 vs. (Class 1 and 2)\")\n",
        "print(\"Train Accuracy:\", accuracy_train2)\n",
        "print(\"Test Accuracy:\", accuracy_test2)\n",
        "print(\"Confusion Matrix Train :\")\n",
        "print(confusion_matrix_train)\n",
        "print(\"Confusion Matrix Test :\")\n",
        "print(confusion_matrix_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZfsPRJGr0Th",
        "outputId": "508f08b6-cadb-40bb-c799-22f33c1018bc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier 2 - Class 3 vs. (Class 1 and 2)\n",
            "Train Accuracy: 0.7434640522875817\n",
            "Test Accuracy: 0.5816993464052288\n",
            "Confusion Matrix Train :\n",
            "[[ 90 112]\n",
            " [ 45 365]]\n",
            "Confusion Matrix Test :\n",
            "[[ 6 47]\n",
            " [17 83]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Class 1 vs. Class 2 Classifier\n",
        "lda3 = LinearDiscriminantAnalysis()\n",
        "lda3.fit(X_classifier3_train_csp, y_classifier3_train)\n",
        "\n",
        "# Predict on train and test data\n",
        "y_classifier3_train_pred = lda3.predict(X_classifier3_train_csp)\n",
        "y_classifier3_test_pred = lda3.predict(X_classifier3_test_csp)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_train3 = accuracy_score(y_classifier3_train, y_classifier3_train_pred)\n",
        "accuracy_test3 = accuracy_score(y_classifier3_test, y_classifier3_test_pred)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "confusion_matrix_train = confusion_matrix(y_classifier3_train, y_classifier3_train_pred)\n",
        "confusion_matrix_test = confusion_matrix(y_classifier3_test, y_classifier3_test_pred)\n",
        "\n",
        "print(\"Classifier 3 - Class 1 vs. Class 2\")\n",
        "print(\"Train Accuracy:\", accuracy_train3)\n",
        "print(\"Test Accuracy:\", accuracy_test3)\n",
        "print(\"Confusion Matrix Train :\")\n",
        "print(confusion_matrix_train)\n",
        "print(\"Confusion Matrix Test :\")\n",
        "print(confusion_matrix_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYgYu5tfr5iu",
        "outputId": "f13e4044-2a29-48af-cc1f-adabd6793e10"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier 3 - Class 1 vs. Class 2\n",
            "Train Accuracy: 0.7034313725490197\n",
            "Test Accuracy: 0.6176470588235294\n",
            "Confusion Matrix Train :\n",
            "[[145  57]\n",
            " [ 64 142]]\n",
            "Confusion Matrix Test :\n",
            "[[35 18]\n",
            " [21 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train 15 Models for each Person ( Split LOO)\n",
        "\n",
        "Train 15 model for 15 person ( using CSP and LDA) and print acc and confiussion Matrix"
      ],
      "metadata": {
        "id": "fdMXfFEK_ZFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the channels of interest\n",
        "channels_of_interest = [11, 40, 12, 41, 13, 42, 14, 44, 16, 45, 17, 46, 18, 47, 20, 49, 21, 50, 22, 51, 23]\n",
        "\n",
        "# Loop over each person\n",
        "for i in range(1, 16):\n",
        "  print(\"-------------------------------------------------------------------\")\n",
        "  print(\"Person\", i)\n",
        "  print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "  ## load data \n",
        "\n",
        "  # Initialize empty lists for X and Y data\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  # Load the .mat file for each person\n",
        "  data = loadmat(f'dataset/subj_{i}.mat')['data'][0]\n",
        "  min_num_trials = float('inf')  # Initialize with a large value\n",
        "\n",
        "  # Extract the classes\n",
        "  class_1 = data[0][:, channels_of_interest, :]\n",
        "  class_2 = data[1][:, channels_of_interest, :]\n",
        "  class_3 = data[2][:, channels_of_interest, :]\n",
        "  class_4 = data[3][:, channels_of_interest, :]\n",
        "\n",
        "  # Determine the minimum number of trials among all classes\n",
        "  min_num_trials = min(min_num_trials, class_1.shape[2], class_2.shape[2], class_3.shape[2], class_4.shape[2])\n",
        "\n",
        "  # Append the data to X and Y\n",
        "  X.append(class_1[:, :, :min_num_trials])\n",
        "  X.append(class_2[:, :, :min_num_trials])\n",
        "  X.append(class_3[:, :, :min_num_trials])\n",
        "  X.append(class_4[:, :, :min_num_trials])\n",
        "\n",
        "  # Create labels for the classes\n",
        "  num_samples = min_num_trials * 4\n",
        "  labels = np.zeros((num_samples,))\n",
        "  labels[min_num_trials:min_num_trials * 2] = 1\n",
        "  labels[min_num_trials * 2:min_num_trials * 3] = 2\n",
        "  labels[min_num_trials * 3:] = 3\n",
        "\n",
        "  # Append the labels to Y\n",
        "  Y.append(labels)\n",
        "\n",
        "  X = np.concatenate(X, axis=2)\n",
        "  Y = np.concatenate(Y, axis=0)\n",
        "  X = X.transpose((2, 1, 0))\n",
        "\n",
        "  ## Leave one Out Split\n",
        "\n",
        "  # Initialize lists for train and test sets\n",
        "  X_train = []\n",
        "  X_test = []\n",
        "  Y_train = []\n",
        "  Y_test = []\n",
        "\n",
        "  # Split the data using leave-one-out method\n",
        "  for i in range(min_num_trials):\n",
        "      X_train.append(np.concatenate([X[Y != j, :, :] for j in range(4)], axis=0))\n",
        "      X_test.append(X[Y == i, :, :])\n",
        "      Y_train.append(np.concatenate([Y[Y != j] for j in range(4)], axis=0))\n",
        "      Y_test.append(Y[Y == i])\n",
        "\n",
        "  # Convert lists to arrays\n",
        "  X_train = np.concatenate(X_train, axis=0)\n",
        "  X_test = np.concatenate(X_test, axis=0)\n",
        "  Y_train = np.concatenate(Y_train, axis=0)\n",
        "  Y_test = np.concatenate(Y_test, axis=0)\n",
        "\n",
        "  # Create separate datasets for each class\n",
        "  X1_train = X_train[Y_train == 0]\n",
        "  X2_train = X_train[Y_train == 1]\n",
        "  X3_train = X_train[Y_train == 2]\n",
        "  X4_train = X_train[Y_train == 3]\n",
        "\n",
        "  X1_train = X1_train[np.logical_not(np.isnan(np.sum(X1_train, axis=(1, 2))) | np.isinf(np.sum(X1_train, axis=(1, 2))))]\n",
        "  X2_train = X2_train[np.logical_not(np.isnan(np.sum(X2_train, axis=(1, 2))) | np.isinf(np.sum(X2_train, axis=(1, 2))))]\n",
        "  X3_train = X3_train[np.logical_not(np.isnan(np.sum(X3_train, axis=(1, 2))) | np.isinf(np.sum(X3_train, axis=(1, 2))))]\n",
        "  X4_train = np.nan_to_num(X4_train)\n",
        "\n",
        "  X1_test = X_test[Y_test == 0]\n",
        "  X2_test = X_test[Y_test == 1]\n",
        "  X3_test = X_test[Y_test == 2]\n",
        "  X4_test = X_test[Y_test == 3]\n",
        "\n",
        "  X1_test = X1_test[np.logical_not(np.isnan(np.sum(X1_test, axis=(1, 2))) | np.isinf(np.sum(X1_test, axis=(1, 2))))]\n",
        "  X2_test = X2_test[np.logical_not(np.isnan(np.sum(X2_test, axis=(1, 2))) | np.isinf(np.sum(X2_test, axis=(1, 2))))]\n",
        "  X3_test = X3_test[np.logical_not(np.isnan(np.sum(X3_test, axis=(1, 2))) | np.isinf(np.sum(X3_test, axis=(1, 2))))]\n",
        "  X4_test = np.nan_to_num(X4_test)\n",
        "\n",
        "  ## Create 3 Classifiers\n",
        "\n",
        "  # Class 4 vs. Other Classes Classifier\n",
        "  X_classifier1_train = np.concatenate((X1_train, X2_train, X3_train, X4_train), axis=0)\n",
        "  y_classifier1_train = np.concatenate((np.ones(X1_train.shape[0]), np.ones(X2_train.shape[0]),\n",
        "                                        np.ones(X3_train.shape[0]), np.zeros(X4_train.shape[0])))\n",
        "\n",
        "  X_classifier1_test = np.concatenate((X1_test, X2_test, X3_test, X4_test), axis=0)\n",
        "  y_classifier1_test = np.concatenate((np.ones(X1_test.shape[0]), np.ones(X2_test.shape[0]),\n",
        "                                      np.ones(X3_test.shape[0]), np.zeros(X4_test.shape[0])))\n",
        "\n",
        "  # Apply CSP to X_classifier1 train and test data\n",
        "  csp1 = CSP(n_components=32, reg=None, log=True)\n",
        "  X_classifier1_train_csp = csp1.fit_transform(X_classifier1_train, y_classifier1_train)\n",
        "  X_classifier1_test_csp = csp1.transform(X_classifier1_test)\n",
        "\n",
        "  # Train LDA on X_classifier1 train data\n",
        "  lda1 = LinearDiscriminantAnalysis()\n",
        "  lda1.fit(X_classifier1_train_csp, y_classifier1_train)\n",
        "\n",
        "  # Predict on train and test data\n",
        "  y_classifier1_train_pred = lda1.predict(X_classifier1_train_csp)\n",
        "  y_classifier1_test_pred = lda1.predict(X_classifier1_test_csp)\n",
        "\n",
        "  # Calculate accuracy for Class 4 vs. Other Classes Classifier\n",
        "  accuracy_train1 = accuracy_score(y_classifier1_train, y_classifier1_train_pred)\n",
        "  accuracy_test1 = accuracy_score(y_classifier1_test, y_classifier1_test_pred)\n",
        "\n",
        "  # Calculate confusion matrices for Class 4 vs. Other Classes Classifier\n",
        "  confusion_matrix_train1 = confusion_matrix(y_classifier1_train, y_classifier1_train_pred)\n",
        "  confusion_matrix_test1 = confusion_matrix(y_classifier1_test, y_classifier1_test_pred)\n",
        "\n",
        "  # Class 3 vs. (Class 1 and 2) Classifier\n",
        "  X_classifier2_train = np.concatenate((X3_train, X1_train, X2_train), axis=0)\n",
        "  y_classifier2_train = np.concatenate((np.zeros(X3_train.shape[0]), np.ones(X1_train.shape[0]),\n",
        "                                        np.ones(X2_train.shape[0])))\n",
        "\n",
        "  X_classifier2_test = np.concatenate((X3_test, X1_test, X2_test), axis=0)\n",
        "  y_classifier2_test = np.concatenate((np.zeros(X3_test.shape[0]), np.ones(X1_test.shape[0]),\n",
        "                                      np.ones(X2_test.shape[0])))\n",
        "\n",
        "  # Apply CSP to X_classifier2 train and test data\n",
        "  csp2 = CSP(n_components=32, reg=None, log=True)\n",
        "  X_classifier2_train_csp = csp2.fit_transform(X_classifier2_train, y_classifier2_train)\n",
        "  X_classifier2_test_csp = csp2.transform(X_classifier2_test)\n",
        "\n",
        "  # Train LDA on X_classifier2 train data\n",
        "  lda2 = LinearDiscriminantAnalysis()\n",
        "  lda2.fit(X_classifier2_train_csp, y_classifier2_train)\n",
        "\n",
        "  # Predict on train and test data\n",
        "  y_classifier2_train_pred = lda2.predict(X_classifier2_train_csp)\n",
        "  y_classifier2_test_pred = lda2.predict(X_classifier2_test_csp)\n",
        "\n",
        "  # Calculate accuracy for Class 3 vs. (Class 1 and 2) Classifier\n",
        "  accuracy_train2 = accuracy_score(y_classifier2_train, y_classifier2_train_pred)\n",
        "  accuracy_test2 = accuracy_score(y_classifier2_test, y_classifier2_test_pred)\n",
        "\n",
        "  # Calculate confusion matrices for Class 3 vs. (Class 1 and 2) Classifier\n",
        "  confusion_matrix_train2 = confusion_matrix(y_classifier2_train, y_classifier2_train_pred)\n",
        "  confusion_matrix_test2 = confusion_matrix(y_classifier2_test, y_classifier2_test_pred)\n",
        "\n",
        "  # Class 1 vs. Class 2 Classifier\n",
        "  X_classifier3_train = np.concatenate((X1_train, X2_train), axis=0)\n",
        "  y_classifier3_train = np.concatenate((np.zeros(X1_train.shape[0]), np.ones(X2_train.shape[0])))\n",
        "\n",
        "  X_classifier3_test = np.concatenate((X1_test, X2_test), axis=0)\n",
        "  y_classifier3_test = np.concatenate((np.zeros(X1_test.shape[0]), np.ones(X2_test.shape[0])))\n",
        "\n",
        "  # Apply CSP to X_classifier3 train and test data\n",
        "  csp3 = CSP(n_components=32, reg=None, log=True)\n",
        "  X_classifier3_train_csp = csp3.fit_transform(X_classifier3_train, y_classifier3_train)\n",
        "  X_classifier3_test_csp = csp3.transform(X_classifier3_test)\n",
        "\n",
        "  # Train LDA on X_classifier3 train data\n",
        "  lda3 = LinearDiscriminantAnalysis()\n",
        "  lda3.fit(X_classifier3_train_csp, y_classifier3_train)\n",
        "\n",
        "  # Predict on train and test data\n",
        "  y_classifier3_train_pred = lda3.predict(X_classifier3_train_csp)\n",
        "  y_classifier3_test_pred = lda3.predict(X_classifier3_test_csp)\n",
        "\n",
        "  # Calculate accuracy for Class 1 vs. Class 2 Classifier\n",
        "  accuracy_train3 = accuracy_score(y_classifier3_train, y_classifier3_train_pred)\n",
        "  accuracy_test3 = accuracy_score(y_classifier3_test, y_classifier3_test_pred)\n",
        "\n",
        "  # Calculate confusion matrices for Class 1 vs. Class 2 Classifier\n",
        "  confusion_matrix_train3 = confusion_matrix(y_classifier3_train, y_classifier3_train_pred)\n",
        "  confusion_matrix_test3 = confusion_matrix(y_classifier3_test, y_classifier3_test_pred)\n",
        "\n",
        "  # Combine all X train and test data\n",
        "  X_all_train = np.concatenate((X1_train, X2_train, X3_train, X4_train), axis=0)\n",
        "  X_all_test = np.concatenate((X1_test, X2_test, X3_test, X4_test), axis=0)\n",
        "\n",
        "  # Combine all y train and test data\n",
        "  y_all_train = np.concatenate((np.zeros(X1_train.shape[0]), np.ones(X2_train.shape[0]), np.ones(X3_train.shape[0])*2, np.ones(X4_train.shape[0])*3))\n",
        "  y_all_test = np.concatenate((np.zeros(X1_test.shape[0]), np.ones(X2_test.shape[0]), np.ones(X3_test.shape[0])*2, np.ones(X4_test.shape[0])*3))\n",
        "\n",
        "  ## Evaluate on All Test and Train\n",
        "\n",
        "  # Evaluate the cascade of classifiers on the test data\n",
        "  y_pred_all_train = []\n",
        "  y_pred_all_test = []\n",
        "\n",
        "  for x_train in X_all_train:\n",
        "      x_train_csp1 = csp1.transform(np.array([x_train]))\n",
        "      x_train_csp2 = csp2.transform(np.array([x_train]))\n",
        "      x_train_csp3 = csp3.transform(np.array([x_train]))\n",
        "\n",
        "      if lda1.predict(x_train_csp1) == 1:\n",
        "          if lda2.predict(x_train_csp2) == 1:\n",
        "              if lda3.predict(x_train_csp3) == 1:\n",
        "                  y_pred_all_train.append(1)\n",
        "              else:\n",
        "                  y_pred_all_train.append(0)\n",
        "          else:\n",
        "              y_pred_all_train.append(2)\n",
        "      else:\n",
        "          y_pred_all_train.append(3)\n",
        "\n",
        "  for x_test in X_all_test:\n",
        "      x_test_csp1 = csp1.transform(np.array([x_test]))\n",
        "      x_test_csp2 = csp2.transform(np.array([x_test]))\n",
        "      x_test_csp3 = csp3.transform(np.array([x_test]))\n",
        "\n",
        "      if lda1.predict(x_test_csp1) == 1:\n",
        "          if lda2.predict(x_test_csp2) == 1:\n",
        "              if lda3.predict(x_test_csp3) == 1:\n",
        "                  y_pred_all_test.append(1)\n",
        "              else:\n",
        "                  y_pred_all_test.append(0)\n",
        "          else:\n",
        "              y_pred_all_test.append(2)\n",
        "      else:\n",
        "          y_pred_all_test.append(3)\n",
        "\n",
        "  ## Print results\n",
        "\n",
        "  # Print confusion matrix and accuracy for Class 4 vs. Other Classes Classifier\n",
        "  print(\"Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\")\n",
        "  print(confusion_matrix_train1)\n",
        "  print(\"Accuracy for Class 4 vs. Other Classes Classifier (Train):\", accuracy_train1)\n",
        "  print(\"\\nConfusion Matrix for Class 4 vs. Other Classes Classifier (Test):\")\n",
        "  print(confusion_matrix_test1)\n",
        "  print(\"Accuracy for Class 4 vs. Other Classes Classifier (Test):\", accuracy_test1)\n",
        "  print(\"--------------------------------------------------\")\n",
        "\n",
        "  # Print confusion matrix and accuracy for Class 3 vs. (Class 1 and 2) Classifier\n",
        "  print(\"Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\")\n",
        "  print(confusion_matrix_train2)\n",
        "  print(\"Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train):\", accuracy_train2)\n",
        "  print(\"\\nConfusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\")\n",
        "  print(confusion_matrix_test2)\n",
        "  print(\"Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test):\", accuracy_test2)\n",
        "  print(\"--------------------------------------------------\")\n",
        "\n",
        "  # Print confusion matrix and accuracy for Class 1 vs. Class 2 Classifier\n",
        "  print(\"Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\")\n",
        "  print(confusion_matrix_train3)\n",
        "  print(\"Accuracy for Class 1 vs. Class 2 Classifier (Train):\", accuracy_train3)\n",
        "  print(\"\\nConfusion Matrix for Class 1 vs. Class 2 Classifier (Test):\")\n",
        "  print(confusion_matrix_test3)\n",
        "  print(\"Accuracy for Class 1 vs. Class 2 Classifier (Test):\", accuracy_test3)\n",
        "  print(\"--------------------------------------------------\")\n",
        "\n",
        "  # Print accuracy for classifier 2 and 3\n",
        "  print(\"Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train):\", accuracy_train2)\n",
        "  print(\"Accuracy for Class 1 vs. Class 2 Classifier (Train):\", accuracy_train3)\n",
        "\n",
        "  print(\"--------------------------------------------------\")\n",
        "\n",
        "  # Print confusion matrix and accuracy for the cascade of classifiers\n",
        "  print(\"Confusion Matrix for the Cascade of Classifiers (Train):\")\n",
        "  print(confusion_matrix(y_all_train, y_pred_all_train))\n",
        "  print(\"Accuracy for the Cascade of Classifiers (Train):\", accuracy_score(y_all_train, y_pred_all_train))\n",
        "  print(\"\\nConfusion Matrix for the Cascade of Classifiers (Test):\")\n",
        "  print(confusion_matrix(y_all_test, y_pred_all_test))\n",
        "  print(\"Accuracy for the Cascade of Classifiers (Test):\", accuracy_score(y_all_test, y_pred_all_test))\n",
        "\n",
        "  # Print W(CSP) and W(LDA):\n",
        "\n",
        "  # # Retrieve the weights for CSP\n",
        "  # csp1_weights = csp1.filters_\n",
        "  # csp2_weights = csp1.filters_\n",
        "  # csp3_weights = csp1.filters_\n",
        "\n",
        "  # # Retrieve the weights for LDA\n",
        "  # lda1_weights = lda1.coef_\n",
        "  # lda2_weights = lda1.coef_\n",
        "  # lda3_weights = lda1.coef_\n",
        "\n",
        "  # # Print the weights for CSP\n",
        "  # print(\"CSP weights:\")\n",
        "  # print(csp1_weights)\n",
        "  # print(\"----\")\n",
        "  # print(csp2_weights)\n",
        "  # print(\"----\")\n",
        "  # print(csp3_weights)\n",
        "  # print(\"----\")\n",
        "\n",
        "  # # Print the weights for LDA\n",
        "  # print(\"LDA weights:\")\n",
        "  # print(lda1_weights)\n",
        "  # print(\"----\")\n",
        "  # print(lda2_weights)\n",
        "  # print(\"----\")\n",
        "  # print(lda3_weights)\n",
        "  # print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVqr7_5G_aQN",
        "outputId": "44830cce-9f2c-4664-aff3-b295659c8c3c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n",
            "Person 1\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 49 (2.2e-16 eps * 21 dim * 1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 81 (2.2e-16 eps * 21 dim * 1.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 45 (2.2e-16 eps * 21 dim * 9.8e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 67 (2.2e-16 eps * 21 dim * 1.4e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 43 (2.2e-16 eps * 21 dim * 9.2e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 51 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 864  108]\n",
            " [   0 2916]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9722222222222222\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[16  2]\n",
            " [ 0 54]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9722222222222222\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[ 972    0]\n",
            " [   0 1944]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[18  0]\n",
            " [ 0 36]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[972   0]\n",
            " [  0 972]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[18  0]\n",
            " [ 0 18]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[972   0   0   0]\n",
            " [  0 972   0   0]\n",
            " [  0   0 972   0]\n",
            " [108   0   0 864]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9722222222222222\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[18  0  0  0]\n",
            " [ 0 18  0  0]\n",
            " [ 0  0 18  0]\n",
            " [ 2  0  0 16]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9722222222222222\n",
            "-------------------------------------------------------------------\n",
            "Person 2\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 75 (2.2e-16 eps * 21 dim * 1.6e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 97 (2.2e-16 eps * 21 dim * 2.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 59 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 77 (2.2e-16 eps * 21 dim * 1.6e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 52 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 57 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[1026   57]\n",
            " [   0 3249]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9868421052631579\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[18  1]\n",
            " [ 0 57]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9868421052631579\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 2166]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 38]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 1083]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 19]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1083    0    0    0]\n",
            " [   0 1083    0    0]\n",
            " [   0    0 1083    0]\n",
            " [   0    0   57 1026]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9868421052631579\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[19  0  0  0]\n",
            " [ 0 19  0  0]\n",
            " [ 0  0 19  0]\n",
            " [ 0  0  1 18]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9868421052631579\n",
            "-------------------------------------------------------------------\n",
            "Person 3\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e+02 (2.2e-16 eps * 21 dim * 2.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e+02 (2.2e-16 eps * 21 dim * 2.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 57 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 83 (2.2e-16 eps * 21 dim * 1.8e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 59 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 58 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 969  114]\n",
            " [  57 3192]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9605263157894737\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[17  2]\n",
            " [ 1 56]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9605263157894737\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 2166]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 38]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 1083]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 19]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1083    0    0    0]\n",
            " [   0 1026    0   57]\n",
            " [   0    0 1083    0]\n",
            " [  57   57    0  969]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9605263157894737\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[19  0  0  0]\n",
            " [ 0 18  0  1]\n",
            " [ 0  0 19  0]\n",
            " [ 1  1  0 17]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9605263157894737\n",
            "-------------------------------------------------------------------\n",
            "Person 4\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 50 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.2e+02 (2.2e-16 eps * 21 dim * 2.6e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 41 (2.2e-16 eps * 21 dim * 8.7e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e+02 (2.2e-16 eps * 21 dim * 2.4e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e+02 (2.2e-16 eps * 21 dim * 2.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 51 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 918   54]\n",
            " [   0 2916]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9861111111111112\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[17  1]\n",
            " [ 0 54]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9861111111111112\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[ 972    0]\n",
            " [   0 1944]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[18  0]\n",
            " [ 0 36]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[972   0]\n",
            " [  0 972]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[18  0]\n",
            " [ 0 18]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[972   0   0   0]\n",
            " [  0 972   0   0]\n",
            " [  0   0 972   0]\n",
            " [  0  54   0 918]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9861111111111112\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[18  0  0  0]\n",
            " [ 0 18  0  0]\n",
            " [ 0  0 18  0]\n",
            " [ 0  1  0 17]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9861111111111112\n",
            "-------------------------------------------------------------------\n",
            "Person 5\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 59 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 90 (2.2e-16 eps * 21 dim * 1.9e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 55 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 72 (2.2e-16 eps * 21 dim * 1.5e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 58 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 42 (2.2e-16 eps * 21 dim * 8.9e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[1200    0]\n",
            " [   0 3600]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[20  0]\n",
            " [ 0 60]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1140   60]\n",
            " [   0 2400]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.9833333333333333\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  1]\n",
            " [ 0 40]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 0.9833333333333333\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1200    0]\n",
            " [   0 1200]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[20  0]\n",
            " [ 0 20]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.9833333333333333\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1200    0    0    0]\n",
            " [   0 1200    0    0]\n",
            " [  60    0 1140    0]\n",
            " [   0    0    0 1200]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9875\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[20  0  0  0]\n",
            " [ 0 20  0  0]\n",
            " [ 1  0 19  0]\n",
            " [ 0  0  0 20]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9875\n",
            "-------------------------------------------------------------------\n",
            "Person 6\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 85 (2.2e-16 eps * 21 dim * 1.8e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 94 (2.2e-16 eps * 21 dim * 2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 56 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 76 (2.2e-16 eps * 21 dim * 1.6e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 57 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 51 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[1080  120]\n",
            " [   0 3600]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.975\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[18  2]\n",
            " [ 0 60]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.975\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1200    0]\n",
            " [   0 2400]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[20  0]\n",
            " [ 0 40]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1200    0]\n",
            " [   0 1200]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[20  0]\n",
            " [ 0 20]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1200    0    0    0]\n",
            " [   0 1200    0    0]\n",
            " [   0    0 1200    0]\n",
            " [   0   60   60 1080]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.975\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[20  0  0  0]\n",
            " [ 0 20  0  0]\n",
            " [ 0  0 20  0]\n",
            " [ 0  1  1 18]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.975\n",
            "-------------------------------------------------------------------\n",
            "Person 7\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 51 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 80 (2.2e-16 eps * 21 dim * 1.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 49 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 63 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 44 (2.2e-16 eps * 21 dim * 9.4e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 45 (2.2e-16 eps * 21 dim * 9.6e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 765  102]\n",
            " [   0 2601]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9705882352941176\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[15  2]\n",
            " [ 0 51]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9705882352941176\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[ 867    0]\n",
            " [   0 1734]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[17  0]\n",
            " [ 0 34]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[867   0]\n",
            " [  0 867]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[17  0]\n",
            " [ 0 17]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[867   0   0   0]\n",
            " [  0 867   0   0]\n",
            " [  0   0 867   0]\n",
            " [  0   0 102 765]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9705882352941176\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[17  0  0  0]\n",
            " [ 0 17  0  0]\n",
            " [ 0  0 17  0]\n",
            " [ 0  0  2 15]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9705882352941176\n",
            "-------------------------------------------------------------------\n",
            "Person 8\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 54 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 60 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 37 (2.2e-16 eps * 21 dim * 8e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 47 (2.2e-16 eps * 21 dim * 1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 33 (2.2e-16 eps * 21 dim * 7.2e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 33 (2.2e-16 eps * 21 dim * 7.2e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[1026   57]\n",
            " [   0 3249]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9868421052631579\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[18  1]\n",
            " [ 0 57]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9868421052631579\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 2166]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 38]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 1083]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 19]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1083    0    0    0]\n",
            " [   0 1083    0    0]\n",
            " [   0    0 1083    0]\n",
            " [   0   57    0 1026]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9868421052631579\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[19  0  0  0]\n",
            " [ 0 19  0  0]\n",
            " [ 0  0 19  0]\n",
            " [ 0  1  0 18]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9868421052631579\n",
            "-------------------------------------------------------------------\n",
            "Person 9\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 86 (2.2e-16 eps * 21 dim * 1.8e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 73 (2.2e-16 eps * 21 dim * 1.6e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 37 (2.2e-16 eps * 21 dim * 7.8e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 63 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 45 (2.2e-16 eps * 21 dim * 9.7e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 43 (2.2e-16 eps * 21 dim * 9.3e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 969  114]\n",
            " [   0 3249]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9736842105263158\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[17  2]\n",
            " [ 0 57]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9736842105263158\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1083    0]\n",
            " [  57 2109]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.9824561403508771\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  0]\n",
            " [ 1 37]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 0.9824561403508771\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 1083]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 19]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.9824561403508771\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1026    0   57    0]\n",
            " [   0 1083    0    0]\n",
            " [   0    0 1083    0]\n",
            " [   0   57   57  969]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9605263157894737\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[18  0  1  0]\n",
            " [ 0 19  0  0]\n",
            " [ 0  0 19  0]\n",
            " [ 0  1  1 17]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9605263157894737\n",
            "-------------------------------------------------------------------\n",
            "Person 10\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 34 (2.2e-16 eps * 21 dim * 7.3e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 60 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 30 (2.2e-16 eps * 21 dim * 6.4e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 52 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 31 (2.2e-16 eps * 21 dim * 6.5e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 42 (2.2e-16 eps * 21 dim * 9e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 672   96]\n",
            " [   0 2304]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.96875\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[14  2]\n",
            " [ 0 48]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.96875\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[ 768    0]\n",
            " [   0 1536]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[16  0]\n",
            " [ 0 32]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[768   0]\n",
            " [  0 768]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[16  0]\n",
            " [ 0 16]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[768   0   0   0]\n",
            " [  0 768   0   0]\n",
            " [  0   0 768   0]\n",
            " [  0  96   0 672]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.96875\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[16  0  0  0]\n",
            " [ 0 16  0  0]\n",
            " [ 0  0 16  0]\n",
            " [ 0  2  0 14]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.96875\n",
            "-------------------------------------------------------------------\n",
            "Person 11\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 65 (2.2e-16 eps * 21 dim * 1.4e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 92 (2.2e-16 eps * 21 dim * 2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 48 (2.2e-16 eps * 21 dim * 1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 79 (2.2e-16 eps * 21 dim * 1.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 51 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 60 (2.2e-16 eps * 21 dim * 1.3e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 867    0]\n",
            " [ 102 2499]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9705882352941176\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[17  0]\n",
            " [ 2 49]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9705882352941176\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[ 867    0]\n",
            " [   0 1734]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[17  0]\n",
            " [ 0 34]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[867   0]\n",
            " [  0 867]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[17  0]\n",
            " [ 0 17]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[765   0   0 102]\n",
            " [  0 867   0   0]\n",
            " [  0   0 867   0]\n",
            " [  0   0   0 867]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9705882352941176\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[15  0  0  2]\n",
            " [ 0 17  0  0]\n",
            " [ 0  0 17  0]\n",
            " [ 0  0  0 17]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9705882352941176\n",
            "-------------------------------------------------------------------\n",
            "Person 12\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e+02 (2.2e-16 eps * 21 dim * 2.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e+02 (2.2e-16 eps * 21 dim * 2.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 77 (2.2e-16 eps * 21 dim * 1.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e+02 (2.2e-16 eps * 21 dim * 2.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 51 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 87 (2.2e-16 eps * 21 dim * 1.9e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[ 972    0]\n",
            " [  54 2862]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9861111111111112\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[18  0]\n",
            " [ 1 53]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9861111111111112\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[ 972    0]\n",
            " [   0 1944]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[18  0]\n",
            " [ 0 36]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[972   0]\n",
            " [  0 972]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[18  0]\n",
            " [ 0 18]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[972   0   0   0]\n",
            " [  0 972   0   0]\n",
            " [  0   0 918  54]\n",
            " [  0   0   0 972]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9861111111111112\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[18  0  0  0]\n",
            " [ 0 18  0  0]\n",
            " [ 0  0 17  1]\n",
            " [ 0  0  0 18]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9861111111111112\n",
            "-------------------------------------------------------------------\n",
            "Person 13\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 91 (2.2e-16 eps * 21 dim * 2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 65 (2.2e-16 eps * 21 dim * 1.4e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 37 (2.2e-16 eps * 21 dim * 7.9e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 54 (2.2e-16 eps * 21 dim * 1.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 38 (2.2e-16 eps * 21 dim * 8.2e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 38 (2.2e-16 eps * 21 dim * 8.1e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[1200    0]\n",
            " [  60 3540]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 0.9875\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[20  0]\n",
            " [ 1 59]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 0.9875\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1140   60]\n",
            " [  60 2340]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.9666666666666667\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  1]\n",
            " [ 1 39]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 0.9666666666666667\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1200    0]\n",
            " [   0 1200]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[20  0]\n",
            " [ 0 20]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 0.9666666666666667\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1140    0   60    0]\n",
            " [   0 1140    0   60]\n",
            " [  60    0 1140    0]\n",
            " [   0    0    0 1200]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 0.9625\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[19  0  1  0]\n",
            " [ 0 19  0  1]\n",
            " [ 1  0 19  0]\n",
            " [ 0  0  0 20]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 0.9625\n",
            "-------------------------------------------------------------------\n",
            "Person 14\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e+02 (2.2e-16 eps * 21 dim * 2.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 85 (2.2e-16 eps * 21 dim * 1.8e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 50 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 69 (2.2e-16 eps * 21 dim * 1.5e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 52 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 45 (2.2e-16 eps * 21 dim * 9.6e+15  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 3249]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 57]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 2166]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 38]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 1083]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 19]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1083    0    0    0]\n",
            " [   0 1083    0    0]\n",
            " [   0    0 1083    0]\n",
            " [   0    0    0 1083]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 1.0\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[19  0  0  0]\n",
            " [ 0 19  0  0]\n",
            " [ 0  0 19  0]\n",
            " [ 0  0  0 19]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 1.0\n",
            "-------------------------------------------------------------------\n",
            "Person 15\n",
            "-------------------------------------------------------------------\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e+02 (2.2e-16 eps * 21 dim * 2.2e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e+02 (2.2e-16 eps * 21 dim * 2.8e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 53 (2.2e-16 eps * 21 dim * 1.1e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.2e+02 (2.2e-16 eps * 21 dim * 2.5e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 81 (2.2e-16 eps * 21 dim * 1.7e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 87 (2.2e-16 eps * 21 dim * 1.9e+16  max singular value)\n",
            "    Estimated rank (mag): 21\n",
            "    MAG: rank 21 computed from 21 data channels with 0 projectors\n",
            "Reducing data rank from 21 -> 21\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 3249]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 4 vs. Other Classes Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 57]]\n",
            "Accuracy for Class 4 vs. Other Classes Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 2166]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 3 vs. (Class 1 and 2) Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 38]]\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Train):\n",
            "[[1083    0]\n",
            " [   0 1083]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "\n",
            "Confusion Matrix for Class 1 vs. Class 2 Classifier (Test):\n",
            "[[19  0]\n",
            " [ 0 19]]\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Test): 1.0\n",
            "--------------------------------------------------\n",
            "Accuracy for Class 3 vs. (Class 1 and 2) Classifier (Train): 1.0\n",
            "Accuracy for Class 1 vs. Class 2 Classifier (Train): 1.0\n",
            "--------------------------------------------------\n",
            "Confusion Matrix for the Cascade of Classifiers (Train):\n",
            "[[1083    0    0    0]\n",
            " [   0 1083    0    0]\n",
            " [   0    0 1083    0]\n",
            " [   0    0    0 1083]]\n",
            "Accuracy for the Cascade of Classifiers (Train): 1.0\n",
            "\n",
            "Confusion Matrix for the Cascade of Classifiers (Test):\n",
            "[[19  0  0  0]\n",
            " [ 0 19  0  0]\n",
            " [ 0  0 19  0]\n",
            " [ 0  0  0 19]]\n",
            "Accuracy for the Cascade of Classifiers (Test): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-Sz6ylfBjVI"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}